# -*- coding: utf-8 -*-
import os, sys, time, random, json, subprocess, sqlite3
import pandas as pd
import yfinance as yf
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed
from tqdm import tqdm

# ========== åƒæ•¸èˆ‡è·¯å¾‘è¨­å®š ==========
MARKET_CODE = "cn-share"
DATA_SUBDIR = "dayK"
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
# è³‡æ–™å­˜æ”¾è·¯å¾‘
DATA_DIR = os.path.join(BASE_DIR, "data", MARKET_CODE, DATA_SUBDIR)
LIST_DIR = os.path.join(BASE_DIR, "data", MARKET_CODE, "lists")
# æ¸…å–®å¿«å–èˆ‡å¯©è¨ˆè³‡æ–™åº«è·¯å¾‘
CACHE_LIST_PATH = os.path.join(LIST_DIR, "cn_stock_list_cache.json")
AUDIT_DB_PATH = os.path.join(BASE_DIR, "data_warehouse_audit.db")

# ğŸ›¡ï¸ ç©©å®šæ€§è¨­å®šï¼šä¿æŒ 4 åŸ·è¡Œç·’é¿é–‹å°é–
THREADS_CN = 4 
# ğŸ’¡ æ•¸æ“šæ•ˆæœŸï¼š1 å°æ™‚ (3600ç§’) å…§æŠ“éå°±ä¸å†é‡è¤‡è«‹æ±‚ Yahoo
DATA_EXPIRY_SECONDS = 3600

os.makedirs(DATA_DIR, exist_ok=True)
os.makedirs(LIST_DIR, exist_ok=True)

def log(msg: str):
    print(f"{pd.Timestamp.now():%H:%M:%S}: {msg}")

def ensure_pkg(pkg: str):
    """ç¢ºä¿å¿…è¦å¥—ä»¶å·²å®‰è£"""
    try:
        __import__(pkg)
    except ImportError:
        log(f"ğŸ”§ æ­£åœ¨å®‰è£ {pkg}...")
        subprocess.run([sys.executable, "-m", "pip", "install", "-q", pkg])

def init_audit_db():
    """åˆå§‹åŒ–å¯©è¨ˆè³‡æ–™åº«ç´€éŒ„è¡¨"""
    conn = sqlite3.connect(AUDIT_DB_PATH)
    try:
        conn.execute('''CREATE TABLE IF NOT EXISTS sync_audit (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            execution_time TEXT,
            market_id TEXT,
            total_count INTEGER,
            success_count INTEGER,
            fail_count INTEGER,
            success_rate REAL
        )''')
        conn.commit()
    finally:
        conn.close()

def get_cn_list():
    """ç²å– A è‚¡æ¸…å–®ï¼šæ•´åˆæ¥å£èˆ‡å¿«å–"""
    ensure_pkg("akshare")
    import akshare as ak
    threshold = 4500  
    
    # 1. æª¢æŸ¥ä»Šæ—¥æ¸…å–®å¿«å–
    if os.path.exists(CACHE_LIST_PATH):
        try:
            file_mtime = os.path.getmtime(CACHE_LIST_PATH)
            if datetime.fromtimestamp(file_mtime).date() == datetime.now().date():
                with open(CACHE_LIST_PATH, "r", encoding="utf-8") as f:
                    data = json.load(f)
                    if len(data) >= threshold:
                        log(f"ğŸ“¦ è¼‰å…¥ä»Šæ—¥æ¸…å–®å¿«å– (å…± {len(data)} æª”)")
                        return data
        except: pass

    log("ğŸ“¡ å˜—è©¦å¾ Akshare EM æ¥å£æ›´æ–°æ¸…å–®...")
    try:
        df_sh = ak.stock_sh_a_spot_em()
        df_sz = ak.stock_sz_a_spot_em()
        df = pd.concat([df_sh, df_sz], ignore_index=True)
        
        df['code'] = df['ä»£ç '].astype(str).str.zfill(6)
        valid_prefixes = ('000','001','002','003','300','301','600','601','603','605','688')
        df = df[df['code'].str.startswith(valid_prefixes)]
        
        name_col = 'åç§°' if 'åç§°' in df.columns else 'åç¨±'
        res = [f"{row['code']}&{row[name_col]}" for _, row in df.iterrows()]
        
        if len(res) >= threshold:
            with open(CACHE_LIST_PATH, "w", encoding="utf-8") as f:
                json.dump(res, f, ensure_ascii=False)
            return res
    except Exception as e:
        log(f"âš ï¸ æ¥å£å¤±æ•—: {e}")

    if os.path.exists(CACHE_LIST_PATH):
        with open(CACHE_LIST_PATH, "r", encoding="utf-8") as f:
            return json.load(f)
    return ["600519&è²´å·èŒ…å°", "000001&å¹³å®‰éŠ€è¡Œ"]

def download_one(item):
    """å–®æª”ä¸‹è¼‰é‚è¼¯ï¼šæ™ºæ…§å¿«å– + é‡è©¦"""
    try:
        code, name = item.split('&', 1)
        symbol = f"{code}.SS" if code.startswith('6') else f"{code}.SZ"
        out_path = os.path.join(DATA_DIR, f"{code}_{name}.csv")

        # ğŸ’¡ æ™ºæ…§å¿«å–æª¢æŸ¥ (æŠ“éä¸”åœ¨æ•ˆæœŸå…§å‰‡è·³é)
        if os.path.exists(out_path):
            file_age = time.time() - os.path.getmtime(out_path)
            if file_age < DATA_EXPIRY_SECONDS and os.path.getsize(out_path) > 1000:
                return {"status": "exists", "code": code}

        time.sleep(random.uniform(0.7, 1.5)) 
        tk = yf.Ticker(symbol)
        # ä¸‹è¼‰ 2 å¹´æ­·å²ä½œç‚ºå¢é‡ä¾æ“š
        hist = tk.history(period="2y", timeout=25)
        
        if hist is not None and not hist.empty:
            hist.reset_index(inplace=True)
            hist.columns = [c.lower() for c in hist.columns]
            if 'date' in hist.columns:
                hist['date'] = pd.to_datetime(hist['date'], utc=True).dt.tz_localize(None)
            
            hist.to_csv(out_path, index=False, encoding='utf-8-sig')
            return {"status": "success", "code": code}
        return {"status": "empty", "code": code}
    except Exception:
        return {"status": "error", "code": code}

def main():
    start_time = time.time()
    init_audit_db()
    log("ğŸ‡¨ğŸ‡³ ä¸­åœ‹ A è‚¡æ•¸æ“šåŒæ­¥å™¨ (Audit & Cache å¼·åŒ–ç‰ˆ)")
    
    items = get_cn_list()
    log(f"ğŸš€ ç›®æ¨™ç¸½æ•¸: {len(items)} æª”")
    
    stats = {"success": 0, "exists": 0, "empty": 0, "error": 0}
    fail_list = [] # æ”¶é›†å¤±æ•—åå–®

    with ThreadPoolExecutor(max_workers=THREADS_CN) as executor:
        futures = {executor.submit(download_one, it): it for it in items}
        pbar = tqdm(total=len(items), desc="ä¸‹è¼‰é€²åº¦")
        
        for f in as_completed(futures):
            res = f.result()
            s = res.get("status", "error")
            stats[s] += 1
            if s in ["error", "empty"]:
                fail_list.append(res.get("code", "Unknown"))
            pbar.update(1)
        pbar.close()

    total = len(items)
    success = stats['success'] + stats['exists']
    fail = stats['error'] + stats['empty']
    rate = round((success / total * 100), 2) if total > 0 else 0

    # ğŸš€ å¯«å…¥ Audit DB
    conn = sqlite3.connect(AUDIT_DB_PATH)
    try:
        now_ts = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        conn.execute('''INSERT INTO sync_audit 
            (execution_time, market_id, total_count, success_count, fail_count, success_rate)
            VALUES (?, ?, ?, ?, ?, ?)''', (now_ts, MARKET_CODE, total, success, fail, rate))
        conn.commit()
    finally:
        conn.close()

    download_stats = {
        "total": total,
        "success": success,
        "fail": fail,
        "fail_list": fail_list  # å›å‚³çµ¦ notifier é¡¯ç¤º
    }

    duration = (time.time() - start_time) / 60
    log(f"ğŸ“Š åŸ·è¡Œå ±å‘Š: æˆåŠŸ={success}, å¤±æ•—={fail}, æˆåŠŸç‡={rate}%")
    
    return download_stats

if __name__ == "__main__":
    main()
