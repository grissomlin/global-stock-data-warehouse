# -*- coding: utf-8 -*-
import os, sys, sqlite3, json, time, socket, io
import pandas as pd
from datetime import datetime
from google.oauth2 import service_account
from googleapiclient.discovery import build
from googleapiclient.http import MediaFileUpload, MediaIoBaseDownload

# ğŸ’¡ å…¨åŸŸé€¾æ™‚è¨­å®šï¼Œç¢ºä¿å¤§æª”æ¡ˆå‚³è¼¸ä¸ä¸­æ–·
socket.setdefaulttimeout(600)
GDRIVE_FOLDER_ID = '1ltKCQ209k9MFuWV6FIxQ1coinV2fxSyl' 
SERVICE_ACCOUNT_FILE = 'citric-biplane-319514-75fead53b0f5.json'

try:
    from notifier import StockNotifier
    notifier = StockNotifier()
except ImportError:
    notifier = None

import downloader_tw, downloader_us, downloader_cn, downloader_hk, downloader_jp, downloader_kr

# ğŸ“Š æ‡‰æ”¶æ¨™çš„é–€æª» (è¨ˆç®—è¦†è“‹ç‡çš„ç²¾ç¢ºåŸºæº–)
EXPECTED_MIN_STOCKS = {
    'tw': 900, 'us': 5684, 'cn': 5496, 'hk': 2689, 'jp': 4315, 'kr': 2000
}

# ========== Google Drive æ ¸å¿ƒå‡½å¼ (åŠ å…¥é‡è©¦æ©Ÿåˆ¶) ==========

def get_drive_service():
    env_json = os.environ.get('GDRIVE_SERVICE_ACCOUNT')
    try:
        if env_json:
            info = json.loads(env_json)
            creds = service_account.Credentials.from_service_account_info(info, scopes=['https://www.googleapis.com/auth/drive'])
        elif os.path.exists(SERVICE_ACCOUNT_FILE):
            creds = service_account.Credentials.from_service_account_file(SERVICE_ACCOUNT_FILE, scopes=['https://www.googleapis.com/auth/drive'])
        else:
            return None
        return build('drive', 'v3', credentials=creds, cache_discovery=False)
    except Exception as e:
        print(f"âŒ ç„¡æ³•åˆå§‹åŒ– Drive æœå‹™: {e}")
        return None

def download_db_from_drive(service, file_name, retries=3):
    query = f"name = '{file_name}' and '{GDRIVE_FOLDER_ID}' in parents and trashed = false"
    for attempt in range(retries):
        try:
            results = service.files().list(q=query, fields="files(id)", supportsAllDrives=True, includeItemsFromAllDrives=True).execute()
            items = results.get('files', [])
            if not items: return False
            file_id = items[0]['id']
            print(f"ğŸ“¡ æ­£åœ¨ä¸‹è¼‰é›²ç«¯æ•¸æ“š: {file_name}")
            request = service.files().get_media(fileId=file_id)
            fh = io.FileIO(file_name, 'wb')
            downloader = MediaIoBaseDownload(fh, request, chunksize=5*1024*1024)
            done = False
            while not done:
                status, done = downloader.next_chunk()
            return True
        except Exception as e:
            print(f"âš ï¸ ä¸‹è¼‰å¤±æ•— ({attempt+1}/3): {e}")
            time.sleep(5)
    return False

def upload_db_to_drive(service, file_path, retries=3):
    file_name = os.path.basename(file_path)
    media = MediaFileUpload(file_path, mimetype='application/x-sqlite3', resumable=True)
    query = f"name = '{file_name}' and '{GDRIVE_FOLDER_ID}' in parents and trashed = false"
    for attempt in range(retries):
        try:
            results = service.files().list(q=query, fields="files(id)", supportsAllDrives=True, includeItemsFromAllDrives=True).execute()
            items = results.get('files', [])
            if items:
                service.files().update(fileId=items[0]['id'], media_body=media, supportsAllDrives=True).execute()
            else:
                meta = {'name': file_name, 'parents': [GDRIVE_FOLDER_ID]}
                service.files().create(body=meta, media_body=media, supportsAllDrives=True).execute()
            print(f"âœ… ä¸Šå‚³å®Œæˆ: {file_name}")
            return True
        except Exception as e:
            print(f"âš ï¸ ä¸Šå‚³å¤±æ•— ({attempt+1}/3): {e}")
            time.sleep(5)
    return False

# ========== æ•¸æ“šçµ±è¨ˆæ ¸å¿ƒ (ä¿è­‰æ’ˆå–æ‰€æœ‰æ¬„ä½) ==========

def get_db_summary(db_path, market_id, fail_list=None):
    """ç²¾ç¢ºå¾è³‡æ–™åº«æ’ˆå‡ºï¼šè‚¡ç¥¨æ•¸ã€ç¸½ç­†æ•¸ã€åç¨±åŒæ­¥ã€æœ€æ–°æ—¥æœŸ"""
    try:
        conn = sqlite3.connect(db_path)
        # 1. æ’ˆå–æ—¥Kè¡Œæƒ…çµ±è¨ˆ (ç¸½ç­†æ•¸ã€è‚¡ç¥¨æ•¸ã€æœ€æ–°æ—¥æœŸ)
        df_stats = pd.read_sql("SELECT COUNT(DISTINCT symbol) as s, MAX(date) as d2, COUNT(*) as t FROM stock_prices", conn)
        # 2. æ’ˆå–åç¨±åŒæ­¥æª”æ•¸
        info_count = conn.execute("SELECT COUNT(*) FROM stock_info").fetchone()[0]
        conn.close()

        success_count = int(df_stats['s'][0])
        expected = EXPECTED_MIN_STOCKS.get(market_id, 1)
        coverage = (success_count / expected) * 100

        return {
            "market": market_id.upper(),
            "expected": expected,
            "success": success_count,
            "coverage": f"{coverage:.1f}%",
            "end_date": df_stats['d2'][0],
            "total_rows": df_stats['t'][0],
            "names_synced": info_count,
            "fail_list": fail_list if fail_list else [], # ğŸ’¡ é€™è£¡æŠŠå¤±æ•—åå–®å¡é€²å»
            "status": "âœ…" if coverage >= 90 else "âš ï¸"
        }
    except Exception as e:
        print(f"âš ï¸ çµ±è¨ˆæ’ˆå–å¤±æ•—: {e}")
        return None

def main():
    target_market = sys.argv[1].lower() if len(sys.argv) > 1 else None
    module_map = {
        'tw': downloader_tw, 'us': downloader_us, 'cn': downloader_cn,
        'hk': downloader_hk, 'jp': downloader_jp, 'kr': downloader_kr
    }
    markets_to_run = [target_market] if target_market in module_map else module_map.keys()

    service = get_drive_service()
    if not service: return

    all_summaries = []

    for m in markets_to_run:
        db_file = f"{m}_stock_warehouse.db"
        print(f"\n--- ğŸŒ å¸‚å ´å•Ÿå‹•: {m.upper()} ---")

        if not os.path.exists(db_file):
            download_db_from_drive(service, db_file)

        target_module = module_map.get(m)
        
        # ğŸ’¡ ä¿®æ”¹é»ï¼šå‡è¨­ downloader å›å‚³åŸ·è¡Œçµæœ (åŒ…å« fail_list)
        # å¦‚æœä½ çš„ downloader ç›®å‰åªå›å‚³ Noneï¼Œè«‹ç¢ºä¿ downloader çš„ run_sync æœ‰ return fail_list
        execution_results = target_module.run_sync(mode='hot') 
        
        # å–å¾—å¤±æ•—æ¸…å–® (æ”¯æ´èˆŠç‰ˆ downloader è‹¥ç„¡å›å‚³å‰‡è¨­ç‚ºç©º)
        current_fails = []
        if isinstance(execution_results, dict):
            current_fails = execution_results.get('fail_list', [])
        elif isinstance(execution_results, list):
            current_fails = execution_results

        summary = get_db_summary(db_file, m, fail_list=current_fails)
        if summary:
            all_summaries.append(summary)

        # å„ªåŒ–ä¸¦ä¸Šå‚³
        conn = sqlite3.connect(db_file)
        conn.execute("VACUUM")
        conn.close()
        upload_db_to_drive(service, db_file)

    if notifier and all_summaries:
        notifier.send_stock_report_email(all_summaries)

if __name__ == "__main__":
    main()
