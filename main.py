# -*- coding: utf-8 -*-
import os, sys, sqlite3, json, time
import pandas as pd
from datetime import datetime, timedelta
from google.oauth2 import service_account
from googleapiclient.discovery import build
from googleapiclient.http import MediaFileUpload

# å°å…¥é€šçŸ¥èˆ‡ç’°å¢ƒè®Šæ•¸è¼‰å…¥å·¥å…·
from notifier import StockNotifier
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    pass

# åŒ¯å…¥å„åœ‹ä¸‹è¼‰æ¨¡çµ„
import downloader_tw, downloader_us, downloader_cn, downloader_hk, downloader_jp, downloader_kr

# ========== æ ¸å¿ƒè¨­å®š ==========
GDRIVE_FOLDER_ID = '1ltKCQ209k9MFuWV6FIxQ1coinV2fxSyl' 
SERVICE_ACCOUNT_FILE = 'citric-biplane-319514-75fead53b0f5.json'
AUDIT_DB_PATH = "data_warehouse_audit.db"

# åˆå§‹åŒ–é€šçŸ¥å™¨
notifier = StockNotifier()

def get_db_name(market):
    """æ ¹æ“šå¸‚å ´ä»£ç¢¼å‹•æ…‹ç”Ÿæˆæª”æ¡ˆåç¨±"""
    return f"{market}_stock_warehouse.db"

def init_db(db_file):
    """åˆå§‹åŒ–æ•¸æ“šå­˜å„² SQLite"""
    conn = sqlite3.connect(db_file)
    try:
        conn.execute('''CREATE TABLE IF NOT EXISTS stock_prices (
            date TEXT, symbol TEXT, market TEXT, open REAL, high REAL, low REAL, close REAL, volume INTEGER, updated_at TEXT,
            PRIMARY KEY (date, symbol, market))''')
        conn.execute('CREATE INDEX IF NOT EXISTS idx_date_market ON stock_prices (date, market)')
        conn.execute('CREATE INDEX IF NOT EXISTS idx_symbol ON stock_prices (symbol)')
        conn.commit()
    finally:
        conn.close()

def record_audit_log(market_id, stats):
    """
    âœ¨ æ–°å¢ï¼šç´€éŒ„å¯©è¨ˆæ—¥èªŒè‡³ data_warehouse_audit.db
    """
    conn = sqlite3.connect(AUDIT_DB_PATH)
    try:
        conn.execute('''CREATE TABLE IF NOT EXISTS sync_audit (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            execution_time TEXT,
            market_id TEXT,
            total_count INTEGER,
            success_count INTEGER,
            fail_count INTEGER,
            success_rate REAL
        )''')
        
        total = stats.get('total', 0)
        success = stats.get('success', 0)
        fail = stats.get('fail', 0)
        rate = round((success / total * 100), 2) if total > 0 else 0
        
        # ç²å–å°åŒ—æ™‚é–“
        now_ts = (datetime.utcnow() + timedelta(hours=8)).strftime("%Y-%m-%d %H:%M:%S")
        
        conn.execute('''INSERT INTO sync_audit 
            (execution_time, market_id, total_count, success_count, fail_count, success_rate)
            VALUES (?, ?, ?, ?, ?, ?)''', 
            (now_ts, market_id, total, success, fail, rate))
        conn.commit()
        print(f"ğŸ“‹ Audit Log å·²è¨˜éŒ„è‡³ {AUDIT_DB_PATH}")
    except Exception as e:
        print(f"âš ï¸ Audit Log è¨˜éŒ„å¤±æ•—: {e}")
    finally:
        conn.close()

def check_is_first_time(db_file, market):
    if not os.path.exists(db_file): return True
    conn = sqlite3.connect(db_file)
    try:
        cursor = conn.execute("SELECT COUNT(*) FROM stock_prices WHERE market = ?", (market,))
        return cursor.fetchone()[0] == 0
    except: return True
    finally: conn.close()

def update_database(db_file, market, df):
    """å°‡æŠ“å–çš„æ•¸æ“šå­˜å…¥è³‡æ–™åº«ï¼Œä¸¦æ¨™è¨» UTC+8 æ›´æ–°æ™‚é–“"""
    if df is None or df.empty: return
    
    df['market'] = market
    # å¼·åˆ¶ä½¿ç”¨å°åŒ—æ™‚é–“æ¨™è¨˜
    taipei_now = datetime.utcnow() + timedelta(hours=8)
    df['updated_at'] = taipei_now.strftime("%Y-%m-%d %H:%M:%S")
    
    conn = sqlite3.connect(db_file)
    try:
        conn.execute("PRAGMA journal_mode = WAL;")  
        conn.execute("PRAGMA synchronous = OFF;")   
        conn.execute("PRAGMA cache_size = -1000000;")
        df.to_sql('stock_prices', conn, if_exists='append', index=False)
        conn.commit()
        print(f"âœ… {market.upper()}: æˆåŠŸå¯«å…¥ {len(df)} ç­†äº¤æ˜“è¨˜éŒ„")
    except Exception as e:
        print(f"âš ï¸ {market.upper()}: å¯«å…¥æé†’: {e}")
    finally:
        conn.close()

def upload_to_drive(db_file):
    if not os.path.exists(db_file): return False
    env_json = os.environ.get('GDRIVE_SERVICE_ACCOUNT')
    try:
        if env_json:
            info = json.loads(env_json)
            creds = service_account.Credentials.from_service_account_info(info, scopes=['https://www.googleapis.com/auth/drive'])
        elif os.path.exists(SERVICE_ACCOUNT_FILE):
            creds = service_account.Credentials.from_service_account_file(SERVICE_ACCOUNT_FILE, scopes=['https://www.googleapis.com/auth/drive'])
        else: return False
            
        service = build('drive', 'v3', credentials=creds)
        media = MediaFileUpload(db_file, mimetype='application/x-sqlite3', resumable=True)
        query = f"name = '{db_file}' and '{GDRIVE_FOLDER_ID}' in parents and trashed = false"
        files = service.files().list(q=query, fields="files(id)").execute().get('files', [])
        
        if files:
            service.files().update(fileId=files[0]['id'], media_body=media, supportsAllDrives=True).execute()
        else:
            file_metadata = {'name': db_file, 'parents': [GDRIVE_FOLDER_ID]}
            service.files().create(body=file_metadata, media_body=media, supportsAllDrives=True).execute()
        print(f"ğŸš€ {db_file} é›²ç«¯åŒæ­¥æˆåŠŸ")
        return True
    except Exception:
        print(f"âŒ {db_file} åŒæ­¥å¤±æ•—ï¼")
        return False

def main():
    target_market = sys.argv[1].lower() if len(sys.argv) > 1 else None
    
    modules = {
        'tw': downloader_tw.main,
        'us': downloader_us.main,
        'cn': downloader_cn.main,
        'hk': downloader_hk.main,
        'jp': downloader_jp.main,
        'kr': downloader_kr.main
    }

    markets_to_run = [target_market] if target_market in modules else modules.keys()

    for m in markets_to_run:
        try:
            db_file = get_db_name(m)
            print(f"\n--- ğŸŒ å¸‚å ´ä»»å‹™å•Ÿå‹•: {m.upper()} ---")
            
            init_db(db_file)
            is_first = check_is_first_time(db_file, m)
            
            # 1. åŸ·è¡ŒæŠ“å–ä¸¦æ¥æ”¶è©³ç´°çµ±è¨ˆ (stats)
            # å‡è¨­å„æ¨¡çµ„å·²ä¿®æ”¹ç‚º return {"total": x, "success": y, "fail": z, "fail_list": [...]}
            stats = modules[m]() 
            
            # 2. åˆ¤æ–·æ˜¯å¦æˆåŠŸ
            if stats and stats.get('success', 0) > 0:
                # é€™è£¡å‡è¨­ä¸‹è¼‰å™¨æœƒé †ä¾¿å­˜å¥½ CSVï¼Œmain.py è² è²¬å¾ŒçºŒåŒæ­¥æˆ–å…¥åº«
                # å¦‚æœä½ çš„ä¸‹è¼‰å™¨ç›´æ¥å›å‚³ DFï¼Œå‰‡éœ€åœ¨æ­¤èª¿ç”¨ update_database
                
                upload_status = upload_to_drive(db_file)
                
                # 3. ç™¼é€è©³ç´°å ±å‘Š
                notifier.send_stock_report(
                    market_name=m.upper(),
                    img_data=None, # è‹¥æœ‰åœ–è¡¨å¯å‚³å…¥è·¯åŠ‡
                    report_df=pd.DataFrame(), # é€™è£¡å¯å‚³å…¥åˆ†æå¾Œçš„çµæœ
                    text_reports="",
                    stats=stats
                )
                
                # 4. ç´€éŒ„å¯©è¨ˆæ—¥èªŒ
                record_audit_log(m, stats)
            else:
                error_msg = f"âŒ {m.upper()} ç„¡æ•¸æ“šæ›´æ–°æˆ–æŠ“å–å®Œå…¨å¤±æ•—ã€‚"
                print(error_msg)
                notifier.send_telegram(error_msg)
        
        except Exception as e:
            err_detail = f"âŒ {m.upper()} åŸ·è¡Œç•°å¸¸: {str(e)}"
            print(err_detail)
            notifier.send_telegram(err_detail)
    
    print("\nâœ¨ ä»»å‹™åœ“æ»¿çµæŸ")

if __name__ == "__main__":
    main()
