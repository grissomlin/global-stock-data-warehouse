# -*- coding: utf-8 -*-
import os, sys, sqlite3, json, time, gzip, shutil, socket, io
import pandas as pd
from datetime import datetime, timedelta
from google.oauth2 import service_account
from googleapiclient.discovery import build
from googleapiclient.http import MediaFileUpload, MediaIoBaseDownload

# ğŸ’¡ å¢åŠ å…¨åŸŸé€£ç·šé€¾æ™‚ï¼Œç¢ºä¿å¤§æª”æ¡ˆå‚³è¼¸ç©©å®š (10åˆ†é˜)
socket.setdefaulttimeout(600)

# å°å…¥é€šçŸ¥èˆ‡ç’°å¢ƒè®Šæ•¸è¼‰å…¥å·¥å…·
from notifier import StockNotifier
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    pass

# åŒ¯å…¥å„åœ‹ä¸‹è¼‰æ¨¡çµ„
import downloader_tw, downloader_us, downloader_cn, downloader_hk, downloader_jp, downloader_kr

# ========== æ ¸å¿ƒåƒæ•¸è¨­å®š ==========
# æ‚¨æä¾›çš„ Folder IDï¼šhttps://drive.google.com/drive/folders/1ltKCQ209k9MFuWV6FIxQ1coinV2fxSyl
GDRIVE_FOLDER_ID = '1ltKCQ209k9MFuWV6FIxQ1coinV2fxSyl' 
SERVICE_ACCOUNT_FILE = 'citric-biplane-319514-75fead53b0f5.json'
AUDIT_DB_PATH = "data_warehouse_audit.db"

# ğŸ“Š æ•¸é‡é–€æª»é è­¦è¨­å®š
EXPECTED_MIN_ROWS = {
    'tw': 900, 'us': 4000, 'cn': 4500, 'hk': 1500, 'jp': 3000, 'kr': 2000
}

notifier = StockNotifier()

def get_drive_service():
    """åˆå§‹åŒ– Google Drive API æœå‹™"""
    env_json = os.environ.get('GDRIVE_SERVICE_ACCOUNT')
    try:
        if env_json:
            info = json.loads(env_json)
            creds = service_account.Credentials.from_service_account_info(info, scopes=['https://www.googleapis.com/auth/drive'])
        elif os.path.exists(SERVICE_ACCOUNT_FILE):
            creds = service_account.Credentials.from_service_account_file(SERVICE_ACCOUNT_FILE, scopes=['https://www.googleapis.com/auth/drive'])
        else:
            return None
        return build('drive', 'v3', credentials=creds, cache_discovery=False)
    except Exception as e:
        print(f"âŒ ç„¡æ³•åˆå§‹åŒ– Drive æœå‹™: {e}")
        return None

# ========== é›²ç«¯èˆ‡ç£ç¢Ÿç¶­è­·æ ¸å¿ƒé‚è¼¯ ==========

def download_backup_from_drive(service, file_name):
    """å¾é›²ç«¯ä¸‹è¼‰ .db.gz ä¸¦å„²å­˜è‡³æœ¬åœ°"""
    query = f"name = '{file_name}' and '{GDRIVE_FOLDER_ID}' in parents and trashed = false"
    results = service.files().list(q=query, fields="files(id)").execute(num_retries=3)
    items = results.get('files', [])
    
    if not items:
        return False

    file_id = items[0]['id']
    print(f"ğŸ“¡ ç™¼ç¾é›²ç«¯å‚™ä»½: {file_name}, æ­£åœ¨ä¸‹è¼‰...")
    request = service.files().get_media(fileId=file_id)
    fh = io.FileIO(file_name, 'wb')
    downloader = MediaIoBaseDownload(fh, request, chunksize=10*1024*1024)
    
    done = False
    while not done:
        status, done = downloader.next_chunk(num_retries=5)
        if status:
            print(f"ğŸ“¥ ä¸‹è¼‰é€²åº¦: {int(status.progress() * 100)}%")
    return True

def decompress_db(gz_file):
    """è§£å£“ç¸® .gz ç‚º .db ä¸¦ç«‹å³åˆªé™¤å£“ç¸®æª”é‡‹æ”¾ç©ºé–“"""
    db_file = gz_file.replace('.gz', '')
    try:
        print(f"ğŸ”“ æ­£åœ¨è§£å£“ {gz_file}...")
        with gzip.open(gz_file, 'rb') as f_in:
            with open(db_file, 'wb') as f_out:
                shutil.copyfileobj(f_in, f_out)
        os.remove(gz_file) 
        return True
    except Exception as e:
        print(f"âŒ è§£å£“å¤±æ•—: {e}")
        return False

def optimize_and_compress(db_file):
    """SQLite å„ªåŒ–èˆ‡ GZIP å£“ç¸®ï¼Œä¸¦æ¸…ç†åŸå§‹æª”"""
    gz_file = f"{db_file}.gz"
    try:
        print(f"ğŸ§¹ åŸ·è¡Œ VACUUM å„ªåŒ– {db_file}...")
        conn = sqlite3.connect(db_file)
        conn.execute("VACUUM")
        conn.close()
        
        print(f"ğŸ“¦ æ­£åœ¨å£“ç¸®ç‚º {gz_file}...")
        with open(db_file, 'rb') as f_in:
            with gzip.open(gz_file, 'wb', compresslevel=6) as f_out:
                shutil.copyfileobj(f_in, f_out)
        
        os.remove(db_file) 
        return gz_file
    except Exception as e:
        print(f"âŒ å£“ç¸®å¤±æ•—: {e}")
        return None

def upload_to_drive(service, file_path):
    """å°‡ .db.gz ä¸Šå‚³è‡³ Google Drive (ä¿®æ­£ Quota èˆ‡ Parents é‚è¼¯)"""
    file_name = os.path.basename(file_path)
    # ä½¿ç”¨ resumable upload è™•ç†å¤§æª”æ¡ˆ
    media = MediaFileUpload(file_path, mimetype='application/gzip', resumable=True, chunksize=10*1024*1024)
    
    try:
        # 1. æœå°‹è©²è³‡æ–™å¤¾ä¸‹æ˜¯å¦å·²æœ‰åŒåæª”æ¡ˆ
        query = f"name = '{file_name}' and '{GDRIVE_FOLDER_ID}' in parents and trashed = false"
        results = service.files().list(q=query, fields="files(id)").execute(num_retries=3)
        items = results.get('files', [])
        
        if items:
            # âœ… æ›´æ–°æ—¢æœ‰æª”æ¡ˆ (ä¸æœƒæ¶ˆè€— Service Account é…é¡)
            file_id = items[0]['id']
            print(f"ğŸ”„ æ­£åœ¨æ›´æ–°é›²ç«¯æª”æ¡ˆ: {file_name} (ID: {file_id})")
            request = service.files().update(fileId=file_id, media_body=media, supportsAllDrives=True)
        else:
            # âœ… å»ºç«‹æ–°æª”æ¡ˆ (å¿…é ˆæŒ‡å®š parents æ‰èƒ½ä½¿ç”¨æ‚¨çš„å€‹äººå¸³è™Ÿé…é¡)
            print(f"ğŸ†• æ­£åœ¨å»ºç«‹æ–°æª”æ¡ˆ: {file_name} åœ¨è³‡æ–™å¤¾ {GDRIVE_FOLDER_ID}")
            file_metadata = {
                'name': file_name, 
                'parents': [GDRIVE_FOLDER_ID] 
            }
            request = service.files().create(body=file_metadata, media_body=media, fields='id', supportsAllDrives=True)

        response = None
        while response is None:
            status, response = request.next_chunk(num_retries=5)
            if status:
                print(f"ğŸ“¤ ä¸Šå‚³é€²åº¦: {int(status.progress() * 100)}%")
        return True
    except Exception as e:
        # æ‹‹å‡ºè©³ç´°éŒ¯èª¤ï¼Œç”± main æ•ç²ä¸¦å¯«å…¥å ±è¡¨
        raise Exception(f"Google Drive API éŒ¯èª¤: {str(e)}")

# ========== ä¸»ç¨‹å¼åŸ·è¡Œå€å¡Š ==========

def main():
    target_market = sys.argv[1].lower() if len(sys.argv) > 1 else None
    module_map = {
        'tw': downloader_tw, 'us': downloader_us, 'cn': downloader_cn,
        'hk': downloader_hk, 'jp': downloader_jp, 'kr': downloader_kr
    }
    markets_to_run = [target_market] if target_market in module_map else module_map.keys()

    service = get_drive_service()
    if not service:
        print("âŒ éŒ¯èª¤ï¼šç„¡æ³•å•Ÿå‹• Drive æœå‹™")
        return

    for m in markets_to_run:
        db_file = f"{m}_stock_warehouse.db"
        gz_file = f"{db_file}.gz"
        stats = {}
        try:
            print(f"\n--- ğŸŒ å¸‚å ´å•Ÿå‹•: {m.upper()} ---")

            # 1. æ¢å¾©å‚™ä»½
            if not os.path.exists(db_file):
                if download_backup_from_drive(service, gz_file):
                    decompress_db(gz_file)
                else:
                    print(f"ğŸ†• å»ºç«‹å…¨æ–°è³‡æ–™åº«...")
                    conn = sqlite3.connect(db_file)
                    conn.execute('''CREATE TABLE IF NOT EXISTS stock_prices (
                        date TEXT, symbol TEXT, market TEXT, open REAL, high REAL, low REAL, close REAL, volume INTEGER, updated_at TEXT,
                        PRIMARY KEY (date, symbol, market))''')
                    conn.close()

            # 2. åŸ·è¡Œä¸‹è¼‰æ¨¡çµ„
            target_module = module_map.get(m)
            stats = target_module.main() 
            
            # 3. è™•ç†åŒæ­¥èˆ‡é€šçŸ¥
            success_count = stats.get('success', 0)
            if success_count > 0:
                final_gz = optimize_and_compress(db_file)
                
                # å˜—è©¦åŒæ­¥é›²ç«¯
                try:
                    if final_gz:
                        upload_to_drive(service, final_gz)
                        os.remove(final_gz)
                    sync_status = "âœ… é›²ç«¯åŒæ­¥æˆåŠŸ"
                except Exception as sync_err:
                    sync_status = f"âŒ é›²ç«¯åŒæ­¥å¤±æ•— ({str(sync_err)})"
                
                # çµ„åˆå ±å‘Šå‚™è¨»
                health_note = f"{sync_status}<br>"
                if m in EXPECTED_MIN_ROWS and success_count < EXPECTED_MIN_ROWS[m]:
                    health_note += f"âš ï¸ <b>[è³‡æ–™ç•°å¸¸]</b> æ›´æ–°å®¶æ•¸ ({success_count}) ä½æ–¼é–€æª» ({EXPECTED_MIN_ROWS[m]})ï¼"
                else:
                    health_note += "âœ… æ•¸æ“šå®Œæ•´åº¦è‰¯å¥½ã€‚"
                
                # å¯„é€æ–°ç‰ˆæ ¼å¼å ±è¡¨
                notifier.send_stock_report(m.upper(), None, pd.DataFrame(), health_note, stats)
            else:
                notifier.send_telegram(f"âŒ {m.upper()} ä»Šæ—¥ç„¡æ•¸æ“šæ›´æ–°ã€‚")

        except Exception as e:
            # ç³»çµ±ç´šå´©æ½°
            err_msg = f"âŒ {m.upper()} ç³»çµ±å´©æ½°: {str(e)}"
            print(err_msg)
            notifier.send_telegram(err_msg)
            if os.path.exists(db_file): os.remove(db_file)
    
    print("\nâœ¨ ä»»å‹™åœ“æ»¿çµæŸ")

if __name__ == "__main__":
    main()
