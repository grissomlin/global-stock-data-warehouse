# -*- coding: utf-8 -*-
import os, sys, sqlite3, json, time, gzip, shutil, socket, io
import pandas as pd
from datetime import datetime
from google.oauth2 import service_account
from googleapiclient.discovery import build
from googleapiclient.http import MediaFileUpload, MediaIoBaseDownload

# ğŸ’¡ å¢åŠ é€£ç·šé€¾æ™‚ï¼Œç¢ºä¿å¤§æª”æ¡ˆå‚³è¼¸ç©©å®š
socket.setdefaulttimeout(600)

# å°å…¥é€šçŸ¥å·¥å…· (å‡è¨­æ‚¨å·²æº–å‚™å¥½ notifier.py)
try:
    from notifier import StockNotifier
    notifier = StockNotifier()
except ImportError:
    notifier = None

# åŒ¯å…¥æ‚¨å‰›å‰›é‡å¯«éçš„å„åœ‹ä¸‹è¼‰æ¨¡çµ„
import downloader_tw, downloader_us, downloader_cn, downloader_hk, downloader_jp, downloader_kr

# ========== æ ¸å¿ƒåƒæ•¸è¨­å®š ==========
GDRIVE_FOLDER_ID = '1ltKCQ209k9MFuWV6FIxQ1coinV2fxSyl' 
SERVICE_ACCOUNT_FILE = 'citric-biplane-319514-75fead53b0f5.json'

# ğŸ“Š æ•¸é‡é–€æª»é è­¦è¨­å®š (ä¾æ“šå„åœ‹ç†±æ•¸æ“šè¦æ¨¡èª¿æ•´)
EXPECTED_MIN_STOCKS = {
    'tw': 900, 'us': 4000, 'cn': 4500, 'hk': 1500, 'jp': 3000, 'kr': 2000
}

def get_drive_service():
    """åˆå§‹åŒ– Google Drive API"""
    env_json = os.environ.get('GDRIVE_SERVICE_ACCOUNT')
    try:
        if env_json:
            info = json.loads(env_json)
            creds = service_account.Credentials.from_service_account_info(info, scopes=['https://www.googleapis.com/auth/drive'])
        elif os.path.exists(SERVICE_ACCOUNT_FILE):
            creds = service_account.Credentials.from_service_account_file(SERVICE_ACCOUNT_FILE, scopes=['https://www.googleapis.com/auth/drive'])
        else:
            return None
        return build('drive', 'v3', credentials=creds, cache_discovery=False)
    except Exception as e:
        print(f"âŒ ç„¡æ³•åˆå§‹åŒ– Drive æœå‹™: {e}")
        return None

# ========== æ¦‚æ³çµ±è¨ˆé‚è¼¯ ==========

def get_db_summary(db_path):
    """ç”¢å‡ºæ‚¨è¦æ±‚çš„æ¦‚æ³çµ±è¨ˆè³‡æ–™"""
    db_file = os.path.basename(db_path)
    try:
        conn = sqlite3.connect(db_path)
        # çµ±è¨ˆè¡Œæƒ…è¡¨
        df_stats = pd.read_sql("""
            SELECT 
                COUNT(DISTINCT symbol) as stock_count, 
                MIN(date) as start_date, 
                MAX(date) as end_date, 
                COUNT(*) as total_rows 
            FROM stock_prices
        """, conn)
        
        # é¡å¤–çµ±è¨ˆï¼šå…¬å¸åç¨±è¦†è“‹ç‡ (ä¾†è‡ªæ–°è¡¨ stock_info)
        info_count = conn.execute("SELECT COUNT(*) FROM stock_info").fetchone()[0]
        conn.close()

        summary = {
            "file": db_file,
            "stocks": df_stats['stock_count'][0],
            "start": df_stats['start_date'][0],
            "end": df_stats['end_date'][0],
            "total": df_stats['total_rows'][0],
            "names_synced": info_count
        }
        return summary
    except Exception as e:
        print(f"âš ï¸ çµ±è¨ˆå¤±æ•— {db_file}: {e}")
        return None

def format_summary_table(summary):
    """æ ¼å¼åŒ–æˆæ‚¨è¦æ±‚çš„æ–‡å­—è¡¨æ ¼æ¨£å¼"""
    if not summary: return "çµ±è¨ˆå¤±æ•—"
    table = (
        f"================================================================================\n"
        f"ğŸ“ˆ å„åœ‹è‚¡ç¥¨è³‡æ–™åº«æ¦‚æ³çµ±è¨ˆè¡¨\n"
        f"================================================================================\n"
        f"æª”æ¡ˆåç¨±: {summary['file']}\n"
        f"è‚¡ç¥¨æ•¸é‡: {summary['stocks']}\n"
        f"æœ€æ—©æ—¥æœŸ: {summary['start']}\n"
        f"æœ€æ–°æ—¥æœŸ: {summary['end']}\n"
        f"ç¸½ç­†æ•¸  : {summary['total']}\n"
        f"åç¨±åŒæ­¥: {summary['names_synced']} æª”\n"
    )
    return table

# ========== é›²ç«¯èˆ‡ç¶­è­·é‚è¼¯ (çœç•¥é‡è¤‡çš„ upload/download å‡½æ•¸ï¼Œèˆ‡æ‚¨åŸæœ¬ä¸€è‡´) ==========
# ... [ä¿ç•™æ‚¨åŸæœ¬çš„ download_backup_from_drive, decompress_db, optimize_and_compress, upload_to_drive] ...

# ========== ä¸»ç¨‹å¼åŸ·è¡Œå€å¡Š ==========

def main():
    # æ±ºå®šè·‘å“ªä¸€åœ‹ (python main.py tw) æˆ–å…¨è·‘
    target_market = sys.argv[1].lower() if len(sys.argv) > 1 else None
    module_map = {
        'tw': downloader_tw, 'us': downloader_us, 'cn': downloader_cn,
        'hk': downloader_hk, 'jp': downloader_jp, 'kr': downloader_kr
    }
    markets_to_run = [target_market] if target_market in module_map else module_map.keys()

    service = get_drive_service()
    
    for m in markets_to_run:
        db_file = f"{m}_stock_warehouse.db"
        gz_file = f"{db_file}.gz"
        
        print(f"\n--- ğŸŒ å¸‚å ´å•Ÿå‹•: {m.upper()} ---")

        # 1. å˜—è©¦æ¢å¾©ç†±æ•¸æ“šå‚™ä»½ (å¾é›²ç«¯æŠ“å› 2020 è‡³ä»Šçš„ DB)
        if not os.path.exists(db_file):
            if not download_backup_from_drive(service, gz_file):
                print(f"ğŸ†• å»ºç«‹å…¨æ–° {m} è³‡æ–™åº«çµæ§‹...")
                # é€™è£¡èª¿ç”¨å„åœ‹çš„ init_db()

        # 2. åŸ·è¡Œä¸‹è¼‰æ¨¡çµ„ (ç†±æ•¸æ“šæ¨¡å¼)
        # æ­¤æ™‚å„åœ‹ä¸‹è¼‰å™¨æœƒåŒæ­¥æ›´æ–°è¡Œæƒ…èˆ‡åç¨±è¡¨
        target_module = module_map.get(m)
        target_module.run_sync(mode='hot') 
        
        # 3. ç”¢å‡ºçµ±è¨ˆå ±è¡¨
        summary = get_db_summary(db_file)
        report_text = format_summary_table(summary)
        print(report_text)

        # 4. å„ªåŒ–ã€å£“ç¸®ä¸¦å›å‚³é›²ç«¯
        final_gz = optimize_and_compress(db_file)
        if final_gz and service:
            upload_to_drive(service, final_gz)
            os.remove(final_gz)
            
        # 5. ç™¼é€é€šçŸ¥
        if notifier:
            # åŠ å…¥æ•¸é‡è­¦ç¤ºé‚è¼¯
            health_status = "âœ… æ­£å¸¸"
            if summary and summary['stocks'] < EXPECTED_MIN_STOCKS.get(m, 0):
                health_status = f"âš ï¸ ç•°å¸¸ (æ•¸é‡ä½æ–¼é æœŸ {EXPECTED_MIN_STOCKS[m]})"
            
            notifier.send_telegram(f"å¸‚å ´: {m.upper()}\nç‹€æ…‹: {health_status}\n{report_text}")

    print("\nâœ¨ å…¨çƒæ•¸æ“šåŒæ­¥ä»»å‹™åœ“æ»¿çµæŸ")

if __name__ == "__main__":
    main()
