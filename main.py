# -*- coding: utf-8 -*-
import os, sys, sqlite3, json, time, socket, io
import pandas as pd
from datetime import datetime
from google.oauth2 import service_account
from googleapiclient.discovery import build
from googleapiclient.http import MediaFileUpload, MediaIoBaseDownload
from dotenv import load_dotenv

# ğŸ’¡ æ ¸å¿ƒä¿®æ­£ï¼šåœ¨æœ¬æ©Ÿè·‘æ™‚ï¼Œå¿…é ˆæ‰‹å‹•è¼‰å…¥ .env æª”æ¡ˆ
load_dotenv() 

# ğŸ’¡ å…¨åŸŸé€¾æ™‚è¨­å®š
socket.setdefaulttimeout(600)
GDRIVE_FOLDER_ID = '1ltKCQ209k9MFuWV6FIxQ1coinV2fxSyl' 
SERVICE_ACCOUNT_FILE = 'citric-biplane-319514-75fead53b0f5.json'

# åˆå§‹åŒ–é€šçŸ¥æ¨¡çµ„
try:
    from notifier import StockNotifier
    notifier = StockNotifier()
    if not os.getenv("TELEGRAM_BOT_TOKEN"):
        print("âš ï¸ è­¦å‘Šï¼šç’°å¢ƒè®Šæ•¸ TELEGRAM_BOT_TOKEN ç‚ºç©ºï¼Œé€šçŸ¥åŠŸèƒ½å°‡å—é™ã€‚")
except Exception as e:
    print(f"âŒ Notifier åˆå§‹åŒ–å¤±æ•—: {e}")
    notifier = None

# åŒ¯å…¥å„åœ‹ä¸‹è¼‰æ¨¡çµ„
import downloader_tw, downloader_us, downloader_cn, downloader_hk, downloader_jp, downloader_kr

# ğŸ“Š æ‡‰æ”¶æ¨™çš„é–€æª»
EXPECTED_MIN_STOCKS = {
    'tw': 900, 'us': 5684, 'cn': 5496, 'hk': 2689, 'jp': 4315, 'kr': 2000
}

# [Google Drive ç›¸é—œå‡½å¼ä¿æŒä¸è®Š]
def get_drive_service():
    env_json = os.environ.get('GDRIVE_SERVICE_ACCOUNT')
    try:
        if env_json:
            info = json.loads(env_json)
            creds = service_account.Credentials.from_service_account_info(info, scopes=['https://www.googleapis.com/auth/drive'])
        elif os.path.exists(SERVICE_ACCOUNT_FILE):
            creds = service_account.Credentials.from_service_account_file(SERVICE_ACCOUNT_FILE, scopes=['https://www.googleapis.com/auth/drive'])
        else:
            print("âŒ æ‰¾ä¸åˆ° Google Drive æ†‘è­‰é‡‘é‘°")
            return None
        return build('drive', 'v3', credentials=creds, cache_discovery=False)
    except Exception as e:
        print(f"âŒ ç„¡æ³•åˆå§‹åŒ– Drive æœå‹™: {e}")
        return None

def download_db_from_drive(service, file_name, retries=3):
    query = f"name = '{file_name}' and '{GDRIVE_FOLDER_ID}' in parents and trashed = false"
    for attempt in range(retries):
        try:
            results = service.files().list(q=query, fields="files(id)", supportsAllDrives=True, includeItemsFromAllDrives=True).execute()
            items = results.get('files', [])
            if not items: return False
            file_id = items[0]['id']
            print(f"ğŸ“¡ æ­£åœ¨å¾é›²ç«¯ä¸‹è¼‰æ•¸æ“šåº«: {file_name}")
            request = service.files().get_media(fileId=file_id)
            fh = io.FileIO(file_name, 'wb')
            downloader = MediaIoBaseDownload(fh, request, chunksize=5*1024*1024)
            done = False
            while not done:
                status, done = downloader.next_chunk()
            return True
        except Exception as e:
            print(f"âš ï¸ ä¸‹è¼‰å¤±æ•— ({attempt+1}/3): {e}")
            time.sleep(5)
    return False

def upload_db_to_drive(service, file_path, retries=3):
    file_name = os.path.basename(file_path)
    media = MediaFileUpload(file_path, mimetype='application/x-sqlite3', resumable=True)
    query = f"name = '{file_name}' and '{GDRIVE_FOLDER_ID}' in parents and trashed = false"
    for attempt in range(retries):
        try:
            results = service.files().list(q=query, fields="files(id)", supportsAllDrives=True, includeItemsFromAllDrives=True).execute()
            items = results.get('files', [])
            if items:
                service.files().update(fileId=items[0]['id'], media_body=media, supportsAllDrives=True).execute()
            else:
                meta = {'name': file_name, 'parents': [GDRIVE_FOLDER_ID]}
                service.files().create(body=meta, media_body=media, supportsAllDrives=True).execute()
            print(f"âœ… ä¸Šå‚³æˆåŠŸ: {file_name}")
            return True
        except Exception as e:
            print(f"âš ï¸ ä¸Šå‚³å¤±æ•— ({attempt+1}/3): {e}")
            time.sleep(5)
    return False

# ğŸ’¡ æ–°å¢ï¼šæª¢æŸ¥è³‡æ–™åº«æœ€æ–°æ—¥æœŸçš„åŠŸèƒ½
def check_needs_update(db_path, market_id):
    """æª¢æŸ¥è³‡æ–™åº«æœ€æ–°äº¤æ˜“æ—¥ï¼Œåˆ¤æ–·æ˜¯å¦éœ€è¦æ›´æ–°"""
    if not os.path.exists(db_path):
        print(f"ğŸ†• {market_id.upper()} è³‡æ–™åº«æª”æ¡ˆä¸å­˜åœ¨ï¼Œæº–å‚™å…¨æ–°åŒæ­¥ã€‚")
        return True
    
    try:
        conn = sqlite3.connect(db_path)
        # æŠ“å–åŸå§‹åƒ¹æ ¼è¡¨ä¸­çš„æœ€æ–°æ—¥æœŸ
        res = conn.execute("SELECT MAX(date) FROM stock_prices").fetchone()
        conn.close()
        
        db_latest_date = res[0] if res and res[0] else None
        if not db_latest_date:
            print(f"âš ï¸ {market_id.upper()} è³‡æ–™åº«å…§ç„¡åƒ¹æ ¼æ•¸æ“šï¼Œéœ€è¦æ›´æ–°ã€‚")
            return True
            
        # å–å¾—ä»Šå¤©æ—¥æœŸ
        today_str = datetime.now().strftime('%Y-%m-%d')
        print(f"ğŸ“… [{market_id.upper()}] è³‡æ–™åº«æœ€æ–°ç´€éŒ„: {db_latest_date} | åŸ·è¡Œç•¶å‰æ—¥æœŸ: {today_str}")
        
        # å¦‚æœæœ€æ–°æ—¥æœŸå·²ç¶“ç­‰æ–¼æˆ–å¤§æ–¼ä»Šå¤©ï¼Œå°±è·³é (ä¾‹å¦‚é€±å…­è·‘ç™¼ç¾é€±äº”å·²æ›´æ–°é)
        if db_latest_date >= today_str:
            print(f"âœ… {market_id.upper()} æ•¸æ“šå·²æ˜¯æœ€æ–°ï¼Œç•¥éä¸‹è¼‰æµç¨‹ã€‚")
            return False
            
        return True
    except Exception as e:
        print(f"âš ï¸ æª¢æŸ¥æ—¥æœŸæ™‚å‡ºéŒ¯: {e}ï¼Œé è¨­åŸ·è¡Œæ›´æ–°ã€‚")
        return True

def get_db_summary(db_path, market_id, fail_list=None):
    if not os.path.exists(db_path):
        return None
    try:
        conn = sqlite3.connect(db_path)
        df_stats = pd.read_sql("SELECT COUNT(DISTINCT symbol) as s, MAX(date) as d2, COUNT(*) as t FROM stock_prices", conn)
        info_count = conn.execute("SELECT COUNT(*) FROM stock_info").fetchone()[0]
        conn.close()

        success_count = int(df_stats['s'][0]) if df_stats['s'][0] else 0
        latest_date = df_stats['d2'][0] if df_stats['d2'][0] else "N/A"
        total_rows = int(df_stats['t'][0]) if df_stats['t'][0] else 0
        
        expected = EXPECTED_MIN_STOCKS.get(market_id, 1)
        coverage = (success_count / expected) * 100
        
        return {
            "market": market_id.upper(),
            "expected": expected,
            "success": success_count,
            "coverage": f"{coverage:.1f}%",
            "end_date": latest_date,
            "total_rows": total_rows,
            "names_synced": info_count,
            "fail_list": fail_list if fail_list else [],
            "status": "âœ…" if coverage >= 90 else "âš ï¸"
        }
    except Exception as e:
        print(f"âš ï¸ {market_id.upper()} æ‘˜è¦æ’ˆå–å¤±æ•—: {e}")
        return None

def main():
    target_market = sys.argv[1].lower() if len(sys.argv) > 1 else None
    module_map = {
        'tw': downloader_tw, 'us': downloader_us, 'cn': downloader_cn,
        'hk': downloader_hk, 'jp': downloader_jp, 'kr': downloader_kr
    }
    
    markets_to_run = [target_market] if target_market in module_map else list(module_map.keys())
    service = get_drive_service()
    
    all_summaries = []

    for m in markets_to_run:
        db_file = f"{m}_stock_warehouse.db"
        print(f"\n--- ğŸŒ å¸‚å ´å•Ÿå‹•: {m.upper()} ---")

        # 1. ä¸‹è¼‰é›²ç«¯å‚™ä»½
        if service and not os.path.exists(db_file):
            download_db_from_drive(service, db_file)

        # ğŸ’¡ æ ¸å¿ƒä¿®æ­£ï¼šåˆ¤æ–·æ˜¯å¦éœ€è¦åŸ·è¡Œ run_sync
        needs_update = check_needs_update(db_file, m)
        
        execution_results = {"has_changed": False, "fail_list": []}
        
        if needs_update:
            target_module = module_map.get(m)
            execution_results = target_module.run_sync(mode='hot') 
        
        # 2. ç²å–æ‘˜è¦ï¼ˆä¸è«–æœ‰ç„¡æ›´æ–°éƒ½è®€å–ç›®å‰è³‡æ–™åº«ç‹€æ…‹ï¼‰
        current_fails = execution_results.get('fail_list', []) if isinstance(execution_results, dict) else []
        has_changed = execution_results.get('has_changed', False) if isinstance(execution_results, dict) else False
        
        summary = get_db_summary(db_file, m, fail_list=current_fails)
        if summary:
            all_summaries.append(summary)
            print(f"ğŸ“Š æ‘˜è¦å·²ç”Ÿæˆ: {m.upper()} (æœ€æ–°æ—¥æœŸ: {summary['end_date']} | è¦†è“‹ç‡: {summary['coverage']})")

        # 3. åªæœ‰çœŸçš„æœ‰è®Šå‹•æ‰ä¸Šå‚³é›²ç«¯
        if service and has_changed:
            print(f"ğŸ”„ åµæ¸¬åˆ°æ•¸æ“šè®Šå‹•ï¼Œæ­£åœ¨å„ªåŒ–ä¸¦åŒæ­¥è‡³é›²ç«¯...")
            conn = sqlite3.connect(db_file)
            conn.execute("VACUUM")
            conn.close()
            upload_db_to_drive(service, db_file)
        else:
            print(f"â­ï¸ {m.upper()} ç„¡è®Šå‹•æˆ–ç•¥éæ›´æ–°ï¼Œè·³éé›²ç«¯ä¸Šå‚³ã€‚")

    print(f"\nğŸ ä»»å‹™å…¨éƒ¨çµæŸã€‚æ”¶é›†åˆ°æ‘˜è¦: {len(all_summaries)} ä»½")
    
    if notifier is not None:
        if len(all_summaries) > 0:
            print("ğŸ“¨ æ­£åœ¨ç™¼é€ç›£æ§å ±å‘Š (Email & Telegram)...")
            success = notifier.send_stock_report_email(all_summaries)
            if success:
                print("âœ¨ é€šå ±æˆåŠŸç™¼é€ã€‚")
            else:
                print("âŒ é€šå ±ç™¼é€å¤±æ•—ã€‚")
        else:
            print("âš ï¸ æ‘˜è¦æ¸…å–®ç‚ºç©ºï¼Œè·³éç™¼é€ã€‚")
    else:
        print("âŒ Notifier ç‰©ä»¶ç‚ºç©ºï¼Œè·³éé€šå ±éšæ®µã€‚")

if __name__ == "__main__":
    main()
