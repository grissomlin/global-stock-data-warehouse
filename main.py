# -*- coding: utf-8 -*-
import os, sys, sqlite3, json, time
import pandas as pd
from datetime import datetime
from google.oauth2 import service_account
from googleapiclient.discovery import build
from googleapiclient.http import MediaFileUpload

# åŒ¯å…¥å„åœ‹ä¸‹è¼‰æ¨¡çµ„
import downloader_tw, downloader_us, downloader_cn, downloader_hk, downloader_jp, downloader_kr

# ========== æ ¸å¿ƒè¨­å®š ==========
DB_FILE = 'global_stock_warehouse.db'
# æœ¬åœ°é‡‘é‘°æª”æ¡ˆè·¯å¾‘
SERVICE_ACCOUNT_FILE = 'citric-biplane-319514-75fead53b0f5.json'
# Google Drive è³‡æ–™å¤¾ ID
GDRIVE_FOLDER_ID = '1ltKCQ209k9MFuWV6FIxQ1coinV2fxSyl' 

def init_db():
    """åˆå§‹åŒ–è³‡æ–™åº«èˆ‡ç´¢å¼•"""
    conn = sqlite3.connect(DB_FILE)
    conn.execute('''CREATE TABLE IF NOT EXISTS stock_prices (
        date TEXT, symbol TEXT, market TEXT, open REAL, high REAL, low REAL, close REAL, volume INTEGER, updated_at TEXT,
        PRIMARY KEY (date, symbol, market))''')
    conn.execute('CREATE INDEX IF NOT EXISTS idx_date_market ON stock_prices (date, market)')
    conn.execute('CREATE INDEX IF NOT EXISTS idx_symbol ON stock_prices (symbol)')
    conn.close()

def check_is_first_time(market):
    """åµæ¸¬è©²å¸‚å ´æ˜¯å¦å·²æœ‰è³‡æ–™"""
    if not os.path.exists(DB_FILE): return True
    conn = sqlite3.connect(DB_FILE)
    try:
        count = conn.execute("SELECT COUNT(*) FROM stock_prices WHERE market = ?", (market,)).fetchone()[0]
        return count == 0
    except:
        return True
    finally:
        conn.close()

def update_database(market, df):
    """è³‡æ–™å¯«å…¥ SQLite"""
    if df is None or df.empty: return
    df['market'] = market
    df['updated_at'] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    conn = sqlite3.connect(DB_FILE)
    try:
        df.to_sql('stock_prices', conn, if_exists='append', index=False)
        print(f"âœ… {market.upper()}: è³‡æ–™åº«å¯«å…¥æˆåŠŸ")
    except Exception:
        print(f"âš ï¸ {market.upper()}: éƒ¨åˆ†é‡è¤‡æ—¥æœŸè³‡æ–™å·²è·³é")
    finally:
        conn.close()

def upload_to_drive():
    """é›²ç«¯åŒæ­¥é‚è¼¯ï¼šåŒ…å«æ·±åº¦è¨ºæ–·æ¨¡å¼"""
    if not os.path.exists(DB_FILE):
        print("âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°è³‡æ–™åº«æª”æ¡ˆï¼Œä¸Šå‚³ä¸­æ­¢ã€‚")
        return

    # 1. å˜—è©¦è®€å–é‡‘é‘°
    env_json = os.environ.get('GDRIVE_SERVICE_ACCOUNT')
    
    try:
        if env_json:
            print("â˜ï¸ [è¨ºæ–·] åµæ¸¬åˆ° GitHub Secrets ç’°å¢ƒè®Šæ•¸ï¼Œé–‹å§‹è§£æ...")
            info = json.loads(env_json)
            creds = service_account.Credentials.from_service_account_info(info, scopes=['https://www.googleapis.com/auth/drive'])
        elif os.path.exists(SERVICE_ACCOUNT_FILE):
            print(f"ğŸ’» [è¨ºæ–·] åµæ¸¬åˆ°æœ¬åœ°é‡‘é‘°æª”æ¡ˆ: {SERVICE_ACCOUNT_FILE}")
            creds = service_account.Credentials.from_service_account_file(SERVICE_ACCOUNT_FILE, scopes=['https://www.googleapis.com/auth/drive'])
        else:
            print("âš ï¸ [è¨ºæ–·] æ‰¾ä¸åˆ°ä»»ä½•é‡‘é‘°ä¾†æºï¼Œè·³éé›²ç«¯åŒæ­¥ã€‚")
            return
            
        # 2. å»ºç«‹ Google Drive æœå‹™
        print("ğŸ“¡ [è¨ºæ–·] æ­£åœ¨å»ºç«‹ Google Drive API é€£ç·š...")
        service = build('drive', 'v3', credentials=creds)
        
        # 3. æª¢æŸ¥æª”æ¡ˆå¤§å°
        file_size_mb = os.path.getsize(DB_FILE) / (1024 * 1024)
        print(f"ğŸ“¦ [è¨ºæ–·] æœ¬åœ°è³‡æ–™åº«å¤§å°: {file_size_mb:.2f} MB")

        # 4. æœå°‹é›²ç«¯ç¾æœ‰æª”æ¡ˆ
        print(f"ğŸ” [è¨ºæ–·] æ­£åœ¨é›²ç«¯æœå°‹æª”æ¡ˆ: {DB_FILE}")
        query = f"name = '{DB_FILE}' and '{GDRIVE_FOLDER_ID}' in parents and trashed = false"
        files = service.files().list(q=query, fields="files(id)", supportsAllDrives=True).execute().get('files', [])
        
        # 5. æº–å‚™åª’é«”ä¸Šå‚³ (é–‹å•Ÿ resumable ä»¥æ”¯æ´å¤§æª”æ¡ˆ)
        media = MediaFileUpload(DB_FILE, mimetype='application/x-sqlite3', resumable=True)
        
        if files:
            file_id = files[0]['id']
            print(f"ğŸ”„ [è¨ºæ–·] ç™¼ç¾ç¾æœ‰æª”æ¡ˆ (ID: {file_id})ï¼Œå•Ÿå‹•è¦†è“‹ä¸Šå‚³...")
            service.files().update(fileId=file_id, media_body=media, supportsAllDrives=True).execute()
        else:
            print("ğŸ†• [è¨ºæ–·] é›²ç«¯ç„¡ç¾æœ‰æª”æ¡ˆï¼Œå•Ÿå‹•å…¨æ–°ä¸Šå‚³...")
            file_metadata = {'name': DB_FILE, 'parents': [GDRIVE_FOLDER_ID]}
            service.files().create(body=file_metadata, media_body=media, supportsAllDrives=True).execute()
            
        print("ğŸš€ [æˆåŠŸ] å…¨çƒæ•¸æ“šå€‰åº«å·²åŒæ­¥è‡³é›²ç«¯ã€‚")

    except Exception as e:
        print("\nğŸ’¥ [å´©æ½°è¨ºæ–·] é›²ç«¯åŒæ­¥éç¨‹ä¸­ç™¼ç”Ÿåš´é‡éŒ¯èª¤ï¼")
        print("-" * 50)
        import traceback
        traceback.print_exc() # é€™æœƒå°å‡ºæœ€è©³ç´°çš„å ±éŒ¯è¡Œæ•¸èˆ‡åŸå› 
        print("-" * 50)

def main():
    init_db()
    
    target_market = sys.argv[1].lower() if len(sys.argv) > 1 else None
    
    modules = {
        'tw': downloader_tw.fetch_tw_market_data,
        'us': downloader_us.fetch_us_market_data,
        'cn': downloader_cn.fetch_cn_market_data,
        'hk': downloader_hk.fetch_hk_market_data,
        'jp': downloader_jp.fetch_jp_market_data,
        'kr': downloader_kr.fetch_kr_market_data
    }

    markets_to_run = [target_market] if target_market in modules else modules.keys()

    for m in markets_to_run:
        print(f"\nğŸŒ å¸‚å ´ä»»å‹™é–‹å§‹: {m.upper()}")
        is_first = check_is_first_time(m)
        df = modules[m](is_first)
        update_database(m, df)
    
    print("\nğŸ æ‰€æœ‰å¸‚å ´æŠ“å–å®Œæˆï¼Œæº–å‚™é€²å…¥åŒæ­¥éšæ®µ...")
    upload_to_drive()
    print("\nâœ¨ ä»»å‹™çµæŸã€‚")

if __name__ == "__main__":
    main()
