# -*- coding: utf-8 -*-
import os, sys, sqlite3, json, time
import pandas as pd
from datetime import datetime, timedelta
from google.oauth2 import service_account
from googleapiclient.discovery import build
from googleapiclient.http import MediaFileUpload

# å°å…¥é€šçŸ¥èˆ‡ç’°å¢ƒè®Šæ•¸è¼‰å…¥å·¥å…·
from notifier import StockNotifier
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    pass

# åŒ¯å…¥å„åœ‹ä¸‹è¼‰æ¨¡çµ„
import downloader_tw, downloader_us, downloader_cn, downloader_hk, downloader_jp, downloader_kr

# ========== æ ¸å¿ƒè¨­å®š ==========
GDRIVE_FOLDER_ID = '1ltKCQ209k9MFuWV6FIxQ1coinV2fxSyl' 
SERVICE_ACCOUNT_FILE = 'citric-biplane-319514-75fead53b0f5.json'
AUDIT_DB_PATH = "data_warehouse_audit.db"

# åˆå§‹åŒ–é€šçŸ¥å™¨
notifier = StockNotifier()

def get_db_name(market):
    return f"{market}_stock_warehouse.db"

def init_db(db_file):
    conn = sqlite3.connect(db_file)
    try:
        conn.execute('''CREATE TABLE IF NOT EXISTS stock_prices (
            date TEXT, symbol TEXT, market TEXT, open REAL, high REAL, low REAL, close REAL, volume INTEGER, updated_at TEXT,
            PRIMARY KEY (date, symbol, market))''')
        conn.execute('CREATE INDEX IF NOT EXISTS idx_date_market ON stock_prices (date, market)')
        conn.execute('CREATE INDEX IF NOT EXISTS idx_symbol ON stock_prices (symbol)')
        conn.commit()
    finally:
        conn.close()

def record_audit_log(market_id, stats):
    conn = sqlite3.connect(AUDIT_DB_PATH)
    try:
        conn.execute('''CREATE TABLE IF NOT EXISTS sync_audit (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            execution_time TEXT,
            market_id TEXT,
            total_count INTEGER,
            success_count INTEGER,
            fail_count INTEGER,
            success_rate REAL
        )''')
        total = stats.get('total', 0)
        success = stats.get('success', 0)
        fail = stats.get('fail', 0)
        rate = round((success / total * 100), 2) if total > 0 else 0
        now_ts = (datetime.utcnow() + timedelta(hours=8)).strftime("%Y-%m-%d %H:%M:%S")
        conn.execute('''INSERT INTO sync_audit (execution_time, market_id, total_count, success_count, fail_count, success_rate)
                        VALUES (?, ?, ?, ?, ?, ?)''', (now_ts, market_id, total, success, fail, rate))
        conn.commit()
    except Exception as e:
        print(f"âš ï¸ Audit Log è¨˜éŒ„å¤±æ•—: {e}")
    finally:
        conn.close()

def upload_to_drive(db_file):
    if not os.path.exists(db_file): return False
    env_json = os.environ.get('GDRIVE_SERVICE_ACCOUNT')
    try:
        if env_json:
            info = json.loads(env_json)
            creds = service_account.Credentials.from_service_account_info(info, scopes=['https://www.googleapis.com/auth/drive'])
        elif os.path.exists(SERVICE_ACCOUNT_FILE):
            creds = service_account.Credentials.from_service_account_file(SERVICE_ACCOUNT_FILE, scopes=['https://www.googleapis.com/auth/drive'])
        else: return False
        service = build('drive', 'v3', credentials=creds)
        media = MediaFileUpload(db_file, mimetype='application/x-sqlite3', resumable=True)
        query = f"name = '{db_file}' and '{GDRIVE_FOLDER_ID}' in parents and trashed = false"
        files = service.files().list(q=query, fields="files(id)").execute().get('files', [])
        if files:
            service.files().update(fileId=files[0]['id'], media_body=media, supportsAllDrives=True).execute()
        else:
            file_metadata = {'name': db_file, 'parents': [GDRIVE_FOLDER_ID]}
            service.files().create(body=file_metadata, media_body=media, supportsAllDrives=True).execute()
        return True
    except: return False

def main():
    target_market = sys.argv[1].lower() if len(sys.argv) > 1 else None
    
    # ğŸ’¡ ä¿®æ”¹é»ï¼šåƒ…å­˜å„²æ¨¡çµ„ç‰©ä»¶ï¼Œä¸è¦åœ¨æ­¤æ™‚å‘¼å« .main
    module_map = {
        'tw': downloader_tw,
        'us': downloader_us,
        'cn': downloader_cn,
        'hk': downloader_hk,
        'jp': downloader_jp,
        'kr': downloader_kr
    }

    markets_to_run = [target_market] if target_market in module_map else module_map.keys()

    for m in markets_to_run:
        try:
            db_file = get_db_name(m)
            print(f"\n--- ğŸŒ å¸‚å ´ä»»å‹™å•Ÿå‹•: {m.upper()} ---")
            
            # ğŸ’¡ ä¿®æ”¹é»ï¼šå‹•æ…‹æª¢æŸ¥è©²æ¨¡çµ„æ˜¯å¦æœ‰ main å‡½å¼
            target_module = module_map.get(m)
            if not hasattr(target_module, 'main'):
                err = f"âŒ éŒ¯èª¤: {m.upper()} çš„ä¸‹è¼‰å™¨æª”æ¡ˆ (downloader_{m}.py) ç¼ºå°‘ main() å‡½å¼ï¼Œè«‹æ›´æ–°è©²æª”æ¡ˆå…§å®¹ã€‚"
                print(err)
                notifier.send_telegram(err)
                continue

            init_db(db_file)
            
            # åŸ·è¡ŒæŠ“å–
            stats = target_module.main() 
            
            if stats and stats.get('success', 0) > 0:
                upload_to_drive(db_file)
                notifier.send_stock_report(market_name=m.upper(), img_data=None, report_df=pd.DataFrame(), text_reports="", stats=stats)
                record_audit_log(m, stats)
            else:
                msg = f"âŒ {m.upper()} æŠ“å–çµæœç‚ºç©ºã€‚"
                print(msg)
                notifier.send_telegram(msg)
        
        except Exception as e:
            err_detail = f"âŒ {m.upper()} åŸ·è¡Œç•°å¸¸: {str(e)}"
            print(err_detail)
            notifier.send_telegram(err_detail)
    
    print("\nâœ¨ ä»»å‹™åœ“æ»¿çµæŸ")

if __name__ == "__main__":
    main()
