# -*- coding: utf-8 -*-
"""
éŸ“åœ‹è‚¡ç¥¨è³‡æ–™åŒæ­¥å™¨ï¼ˆæ”¯æ´ GitHub Actionsï¼‰
- å¾ž FinanceDataReader ç²å–å®Œæ•´è‚¡ç¥¨æ¸…å–®
- å¾ž KRX å®˜æ–¹ Excel ä¸‹è¼‰ç”¢æ¥­åˆ†é¡žï¼ˆìƒìž¥ë²•ì¸ëª©ë¡.xlsï¼‰
- ä½¿ç”¨ yfinance æ‰¹é‡ä¸‹è¼‰æ­·å²è‚¡åƒ¹
- å¯«å…¥ SQLite è³‡æ–™åº«
"""

import os
import io
import time
import random
import sqlite3
import re
import pandas as pd
import yfinance as yf
import requests
import FinanceDataReader as fdr  # âœ… ä¿®æ­£é»žï¼šè£œä¸Šéºæ¼çš„ import
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed
from tqdm import tqdm

# ========== 1. ç’°å¢ƒè¨­å®š ==========
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DB_PATH = os.path.join(BASE_DIR, "kr_stock_warehouse.db")
IS_GITHUB_ACTIONS = os.getenv('GITHUB_ACTIONS') == 'true'

BATCH_SIZE = 40
MAX_WORKERS = 4 if IS_GITHUB_ACTIONS else 10
BATCH_DELAY = (4.0, 8.0) if IS_GITHUB_ACTIONS else (0.5, 1.2)

def log(msg: str):
    """å¼·åˆ¶å³æ™‚è¼¸å‡ºï¼ˆé©åˆ GitHub Actions ç›£æŽ§ï¼‰"""
    print(f"{pd.Timestamp.now():%H:%M:%S}: {msg}", flush=True)


# ========== 2. å¾ž KRX Excel æŠ“å–ç”¢æ¥­åˆ†é¡ž ==========
def fetch_krx_industry_from_excel():
    """
    å¾ž KIND ç³»çµ±ä¸‹è¼‰æœ€æ–°çš„ç”¢æ¥­å°ç…§è¡¨
    """
    log("ðŸ“¡ æ­£åœ¨å¾ž KIND ç³»çµ±ä¸‹è¼‰ç”¢æ¥­æ¸…å–® (Excel æ ¼å¼)...")
    
    # ä½¿ç”¨ KIND çš„ä¸‹è¼‰æŽ¥å£
    url = "http://kind.krx.co.kr/corpgeneral/corpList.do?method=download&searchType=13"
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
    }

    try:
        time.sleep(1.5)  
        r = requests.get(url, headers=headers, timeout=20)
        r.raise_for_status()

        # KIND å›žå‚³çš„æ˜¯ä¸€å€‹å½è£æˆ XLS çš„ HTML è¡¨æ ¼ï¼ŒPandas read_html è™•ç†å®ƒæœ€ç©©å®š
        dfs = pd.read_html(io.BytesIO(r.content))
        if not dfs:
            log("âŒ KIND å›žå‚³å…§å®¹ä¸­æ‰¾ä¸åˆ°è¡¨æ ¼")
            return {}
        
        df = dfs[0]
        log(f"ðŸ“¥ æˆåŠŸç²å– KIND æ¸…å–®ï¼Œå…± {len(df)} ç­†è³‡æ–™")

        # æ¬„ä½æ˜ å°„
        sector_map = {}
        # KIND ä¸‹è¼‰çš„æ¬„ä½é€šå¸¸å›ºå®šï¼š íšŒì‚¬ëª…, ì¢…ëª©ì½”ë“œ, ì—…ì¢…, ì£¼ìš”ì œí’ˆ...
        # æˆ‘å€‘ä¸»è¦éœ€è¦ 'ì¢…ëª©ì½”ë“œ' (ä»£ç¢¼) å’Œ 'ì—…ì¢…' (ç”¢æ¥­)
        
        # å°‹æ‰¾ä»£ç¢¼å’Œç”¢æ¥­çš„æ­£ç¢ºæ¬„ä½åç¨±
        code_col = next((c for c in df.columns if 'ì¢…ëª©ì½”ë“œ' in str(c)), None)
        sector_col = next((c for c in df.columns if 'ì—…ì¢…' in str(c)), None)

        if code_col is None or sector_col is None:
            log(f"âŒ ç„¡æ³•è¾¨è­˜æ¬„ä½ã€‚ç¾æœ‰æ¬„ä½: {df.columns.tolist()}")
            return {}

        for _, row in df.iterrows():
            code = str(row[code_col]).strip().zfill(6)
            sector = str(row[sector_col]).strip()
            if code and sector:
                sector_map[code] = sector

        log(f"âœ… æˆåŠŸè¼‰å…¥ {len(sector_map)} å€‹ç”¢æ¥­å°æ‡‰")
        return sector_map

    except Exception as e:
        log(f"âŒ KIND Excel è§£æžå¤±æ•—: {e}")
        return {}


# ========== 3. ä¸»æ¸…å–®ç²å–ï¼ˆFDR + KIND ç”¢æ¥­ï¼‰==========
def get_kr_stock_list():
    log("ðŸ“¡ æ­£åœ¨æ•´åˆ FinanceDataReader æ¸…å–®èˆ‡ KIND ç”¢æ¥­è³‡æ–™...")
    
    try:
        # ç²å– FDR æ¸…å–®
        df_fdr = fdr.StockListing('KRX')
        log(f"ðŸ“Š FDR ç²å–åˆ° {len(df_fdr)} æª”æ¨™çš„")

        # ç²å–ç”¢æ¥­æ˜ å°„
        kind_sector_map = fetch_krx_industry_from_excel()

        conn = sqlite3.connect(DB_PATH)
        items = []
        valid_sector_count = 0

        for _, row in df_fdr.iterrows():
            code_clean = str(row['Code']).strip().zfill(6)
            
            # åˆ¤æ–·å¸‚å ´å¾Œç¶´
            market = str(row.get('Market', 'Unknown')).strip()
            suffix = ".KS" if market == "KOSPI" else ".KQ"
            symbol = f"{code_clean}{suffix}"
            name = str(row['Name']).strip()

            # å„ªå…ˆæ¬Šï¼šKIND ç”¢æ¥­åˆ¥ > FDR Sector æ¬„ä½ > Unknown
            sector = kind_sector_map.get(code_clean)
            if not sector:
                sector = str(row.get('Sector', '')).strip()
            
            if not sector or sector.lower() in ('nan', 'none', ''):
                sector = "Other/Unknown"
            else:
                valid_sector_count += 1

            conn.execute("""
                INSERT OR REPLACE INTO stock_info (symbol, name, sector, market, updated_at) 
                VALUES (?, ?, ?, ?, ?)
            """, (symbol, name, sector, market, datetime.now().strftime("%Y-%m-%d")))
            
            items.append((symbol, name))

        conn.commit()
        conn.close()

        log(f"âœ… éŸ“è‚¡æ¸…å–®æ•´åˆæˆåŠŸ: {len(items)} æª”ï¼ˆå«æœ‰æ•ˆç”¢æ¥­: {valid_sector_count}ï¼‰")
        return items

    except Exception as e:
        log(f"âŒ æ¸…å–®æ•´åˆå¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return []


# ========== 4. æ‰¹é‡ä¸‹è¼‰è‚¡åƒ¹ (ç¶­æŒåŽŸæœ‰æ•ˆçŽ‡é‚è¼¯) ==========
def download_batch(batch_items, mode):
    symbols = [it[0] for it in batch_items]
    start_date = "2020-01-01" if mode == 'hot' else "2010-01-01"
    try:
        data = yf.download(
            tickers=symbols,
            start=start_date,
            group_by='ticker',
            auto_adjust=True,
            threads=False,
            progress=False,
            timeout=45
        )
        if data.empty:
            return 0

        conn = sqlite3.connect(DB_PATH, timeout=60)
        success = 0
        target_list = symbols if isinstance(symbols, list) else [symbols]

        for symbol in target_list:
            try:
                df = data[symbol].copy() if len(target_list) > 1 else data.copy()
                df.dropna(how='all', inplace=True)
                if df.empty:
                    continue
                df.reset_index(inplace=True)
                df.columns = [c.lower() for c in df.columns]
                date_col = 'date' if 'date' in df.columns else df.columns[0]
                df['date_str'] = pd.to_datetime(df[date_col]).dt.strftime('%Y-%m-%d')
                for _, r in df.iterrows():
                    vol = int(r['volume']) if pd.notna(r['volume']) else 0
                    conn.execute(
                        "INSERT OR REPLACE INTO stock_prices VALUES (?,?,?,?,?,?,?)",
                        (r['date_str'], symbol, r['open'], r['high'], r['low'], r['close'], vol)
                    )
                success += 1
            except Exception:
                continue

        conn.commit()
        conn.close()
        return success
    except Exception:
        return 0


# ========== 5. åˆå§‹åŒ– & ä¸»æµç¨‹ ==========
def init_db():
    conn = sqlite3.connect(DB_PATH)
    conn.execute('''CREATE TABLE IF NOT EXISTS stock_prices (
                        date TEXT, symbol TEXT, open REAL, high REAL, 
                        low REAL, close REAL, volume INTEGER,
                        PRIMARY KEY (date, symbol))''')
    conn.execute('''CREATE TABLE IF NOT EXISTS stock_info (
                        symbol TEXT PRIMARY KEY, name TEXT, sector TEXT, market TEXT, updated_at TEXT)''')
    conn.close()


def run_sync(mode='hot'):
    start_time = time.time()
    init_db()
    
    items = get_kr_stock_list()
    if not items:
        log("ðŸ›‘ ç„¡æœ‰æ•ˆè‚¡ç¥¨æ¸…å–®ï¼Œè·³éŽåŒæ­¥")
        return {"success": 0, "total": 0, "has_changed": False}

    batches = [items[i:i + BATCH_SIZE] for i in range(0, len(items), BATCH_SIZE)]
    log(f"ðŸš€ é–‹å§‹éŸ“è‚¡åŒæ­¥ | ç›®æ¨™: {len(items)} æª” | æ‰¹æ¬¡: {len(batches)}")

    total_success = 0
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        futures = {executor.submit(download_batch, b, mode): b for b in batches}
        for f in tqdm(as_completed(futures), total=len(batches), desc="KRåŒæ­¥"):
            time.sleep(random.uniform(*BATCH_DELAY))
            total_success += f.result()

    log("ðŸ§¹ è³‡æ–™åº«å„ªåŒ–...")
    conn = sqlite3.connect(DB_PATH)
    conn.execute("VACUUM")
    conn.close()
    
    duration = (time.time() - start_time) / 60
    log(f"ðŸ“Š åŒæ­¥å®Œæˆï¼æœ‰æ•ˆæ¨™çš„: {total_success} | è²»æ™‚: {duration:.1f} åˆ†é˜")
    return {"success": total_success, "total": len(items), "has_changed": total_success > 0}


if __name__ == "__main__":
    run_sync()
