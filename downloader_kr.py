# -*- coding: utf-8 -*-
import os, io, time, random, sqlite3, requests, re, json, urllib3
import pandas as pd
import yfinance as yf
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed
from tqdm import tqdm

# ç¦ç”¨ SSL è­¦å‘Š
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# ========== 1. ç’°å¢ƒè¨­å®š ==========
MARKET_CODE = "kr-share"
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DB_PATH = os.path.join(BASE_DIR, "kr_stock_warehouse.db")
IS_GITHUB_ACTIONS = os.getenv('GITHUB_ACTIONS') == 'true'

# å„ªåŒ–æ‰¹æ¬¡è¨­å®š
BATCH_SIZE = 30 if IS_GITHUB_ACTIONS else 50
MAX_WORKERS = 3 if IS_GITHUB_ACTIONS else 8
BATCH_DELAY = (1.5, 3.0) if IS_GITHUB_ACTIONS else (0.3, 0.8)

def log(msg: str):
    print(f"{pd.Timestamp.now():%H:%M:%S}: {msg}")

def init_db():
    """åˆå§‹åŒ–æ•°æ®åº“ï¼Œç¡®ä¿è¡¨ç»“æ„æ­£ç¡®"""
    conn = sqlite3.connect(DB_PATH)
    try:
        conn.execute('''CREATE TABLE IF NOT EXISTS stock_prices (
                            date TEXT, symbol TEXT, open REAL, high REAL, 
                            low REAL, close REAL, volume INTEGER,
                            PRIMARY KEY (date, symbol))''')
        conn.execute('''CREATE TABLE IF NOT EXISTS stock_info (
                            symbol TEXT PRIMARY KEY, name TEXT, sector TEXT, 
                            market TEXT, updated_at TEXT)''')
        cursor = conn.execute("PRAGMA table_info(stock_info)")
        if 'market' not in [col[1] for col in cursor.fetchall()]:
            conn.execute("ALTER TABLE stock_info ADD COLUMN market TEXT")
            conn.commit()
    finally:
        conn.close()

# ========== 2. å¤šä¾†æºéŸ“åœ‹è‚¡ç¥¨æ¸…å–®ç²å– ==========

def normalize_kr_code(code: str) -> str:
    """æ­£è¦åŒ–éŸ“åœ‹è‚¡ç¥¨ä»£ç¢¼ç‚º6ä½æ•¸å­—"""
    if not code:
        return ""
    # ç§»é™¤æ‰€æœ‰éæ•¸å­—å­—ç¬¦
    digits = re.sub(r'[^0-9]', '', str(code))
    # è£œé›¶è‡³6ä½
    return digits.zfill(6) if digits else ""

def fetch_krx_list_primary():
    """
    ä¸»è¦æ–¹æ³•ï¼šä½¿ç”¨ KRX çš„å…¬é–‹APIç²å–è‚¡ç¥¨æ¸…å–®
    å˜—è©¦å¤šå€‹å¯èƒ½çš„APIç«¯é»
    """
    endpoints = [
        {
            'name': 'MDCSTAT04301',  # ä¸Šå¸‚è­‰åˆ¸ç¾ç‹€
            'url': 'dbms/MDC/STAT/standard/MDCSTAT04301',
            'params': {
                'locale': 'ko_KR',
                'mktId': 'STK',  # STK=è‚¡ç¥¨, KSQ=KOSDAQ
                'trdDd': datetime.now().strftime('%Y%m%d'),
                'share': '1',
                'money': '1',
                'csvxls_isNo': 'false'
            }
        },
        {
            'name': 'MDCSTAT03402',  # è‚¡ç¥¨å¸‚å ´ç¾ç‹€ï¼ˆå‚™ç”¨ï¼‰
            'url': 'dbms/MDC/STAT/standard/MDCSTAT03402',
            'params': {
                'locale': 'ko_KR',
                'mktId': 'ALL',
                'share': '1',
                'csvxls_isNo': 'false'
            }
        }
    ]
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
        'Referer': 'http://data.krx.co.kr/contents/MDC/MDI/mdiLoader',
        'Accept': 'text/csv,application/csv,text/plain'
    }
    
    for endpoint in endpoints:
        try:
            log(f"å˜—è©¦ KRX API: {endpoint['name']}")
            
            # 1. ç²å– OTP
            otp_url = "http://data.krx.co.kr/comm/fileDn/GenerateOTP/generate.cmd"
            otp_response = requests.post(
                otp_url, 
                data=endpoint['params'], 
                headers=headers, 
                timeout=15,
                verify=False
            )
            
            if otp_response.status_code != 200:
                log(f"  OTPç²å–å¤±æ•—: {otp_response.status_code}")
                continue
                
            otp_code = otp_response.text.strip()
            if not otp_code:
                log("  OTPç‚ºç©º")
                continue
            
            # 2. ä¸‹è¼‰ CSV
            download_url = "http://data.krx.co.kr/comm/fileDn/download_csv/download.cmd"
            csv_response = requests.post(
                download_url,
                data={'code': otp_code},
                headers=headers,
                timeout=30,
                verify=False
            )
            
            if csv_response.status_code != 200:
                log(f"  CSVä¸‹è¼‰å¤±æ•—: {csv_response.status_code}")
                continue
            
            # è™•ç†ç·¨ç¢¼ (KRX ä½¿ç”¨ cp949)
            csv_response.encoding = 'cp949'
            content = csv_response.text
            
            if not content or len(content.strip()) < 100:
                log(f"  å›å‚³å…§å®¹éçŸ­: {len(content)} å­—ç¬¦")
                continue
            
            # 3. è§£æ CSV
            df = pd.read_csv(io.StringIO(content))
            
            if df.empty or len(df) < 10:
                log(f"  æ•¸æ“šç‚ºç©ºæˆ–éå°‘: {len(df)} è¡Œ")
                continue
            
            log(f"âœ… æˆåŠŸå¾ {endpoint['name']} ç²å– {len(df)} ç­†æ•¸æ“š")
            return df
            
        except Exception as e:
            log(f"  {endpoint['name']} å¤±æ•—: {str(e)[:100]}")
            continue
    
    return None

def fetch_fallback_list():
    """
    å‚™ç”¨æ–¹æ³•ï¼šç•¶KRX APIå¤±æ•—æ™‚ï¼Œä½¿ç”¨å·²çŸ¥çš„å¤§å‹è‚¡åˆ—è¡¨
    ä¾†æºï¼šéŸ“åœ‹å¸‚å€¼å‰100å¤§å…¬å¸ + ä¸»è¦ETF
    """
    fallback_stocks = [
        # æ ¼å¼: (ä»£ç¢¼, åç¨±, ç”¢æ¥­, å¸‚å ´)
        ("005930", "ì‚¼ì„±ì „ì", "ì „ê¸°ì „ì", "KOSPI"),
        ("000660", "SKí•˜ì´ë‹‰ìŠ¤", "ì „ê¸°ì „ì", "KOSPI"),
        ("035420", "NAVER", "ì„œë¹„ìŠ¤ì—…", "KOSPI"),
        ("051910", "LGí™”í•™", "í™”í•™", "KOSPI"),
        ("005380", "í˜„ëŒ€ì°¨", "ìš´ìˆ˜ì¥ë¹„", "KOSPI"),
        ("035720", "ì¹´ì¹´ì˜¤", "ì„œë¹„ìŠ¤ì—…", "KOSPI"),
        ("000270", "ê¸°ì•„", "ìš´ìˆ˜ì¥ë¹„", "KOSPI"),
        ("068270", "ì…€íŠ¸ë¦¬ì˜¨", "ì˜ì•½í’ˆ", "KOSPI"),
        ("028260", "ì‚¼ì„±ë¬¼ì‚°", "ê±´ì„¤ì—…", "KOSPI"),
        ("012330", "í˜„ëŒ€ëª¨ë¹„ìŠ¤", "ìš´ìˆ˜ì¥ë¹„", "KOSPI"),
        ("105560", "KBê¸ˆìœµ", "ê¸ˆìœµì—…", "KOSPI"),
        ("055550", "ì‹ í•œì§€ì£¼", "ê¸ˆìœµì—…", "KOSPI"),
        ("009150", "ì‚¼ì„±ì „ê¸°", "ì „ê¸°ì „ì", "KOSPI"),
        ("032830", "ì‚¼ì„±ìƒëª…", "ë³´í—˜ì—…", "KOSPI"),
        ("034730", "SK", "í™”í•™", "KOSPI"),
        ("086790", "í•˜ë‚˜ê¸ˆìœµì§€ì£¼", "ê¸ˆìœµì—…", "KOSPI"),
        ("247540", "ì—ì½”í”„ë¡œë¹„ì— ", "ì „ê¸°ì „ì", "KOSDAQ"),
        ("066570", "LGì „ì", "ì „ê¸°ì „ì", "KOSPI"),
        ("003550", "LG", "í™”í•™", "KOSPI"),
        ("096770", "SKì´ë…¸ë² ì´ì…˜", "í™”í•™", "KOSPI"),
        ("352820", "í•˜ì´ë¸Œ", "ì„œë¹„ìŠ¤ì—…", "KOSPI"),
        ("259960", "í¬ë˜í”„í†¤", "ì„œë¹„ìŠ¤ì—…", "KOSPI"),
        ("207940", "ì‚¼ì„±ë°”ì´ì˜¤ë¡œì§ìŠ¤", "ì˜ì•½í’ˆ", "KOSPI"),
        ("036570", "ì—”ì”¨ì†Œí”„íŠ¸", "ì„œë¹„ìŠ¤ì—…", "KOSPI"),
        ("017670", "SKí…”ë ˆì½¤", "í†µì‹ ì—…", "KOSPI"),
    ]
    
    # è½‰æ›ç‚ºDataFrameæ ¼å¼
    data = []
    for code, name, sector, market in fallback_stocks:
        data.append({
            'ì¢…ëª©ì½”ë“œ': code,
            'ì¢…ëª©ëª…': name,
            'ì‹œì¥êµ¬ë¶„': market,
            'ì—…ì¢…ëª…': sector
        })
    
    return pd.DataFrame(data)

def parse_krx_data(df):
    """è§£æKRXæ•¸æ“šï¼Œæå–è‚¡ç¥¨ä¿¡æ¯"""
    if df is None or df.empty:
        log("âŒ ç„¡æœ‰æ•ˆæ•¸æ“šå¯è§£æ")
        return []
    
    # å˜—è©¦è­˜åˆ¥æ¬„ä½åç¨± (éŸ“æ–‡)
    code_col = None
    name_col = None
    market_col = None
    sector_col = None
    
    for col in df.columns:
        col_str = str(col).strip()
        if 'ì¢…ëª©ì½”ë“œ' in col_str or 'ë‹¨ì¶•ì½”ë“œ' in col_str:
            code_col = col
        elif 'ì¢…ëª©ëª…' in col_str or 'ê¸°ì—…ëª…' in col_str:
            name_col = col
        elif 'ì‹œì¥êµ¬ë¶„' in col_str or 'ì‹œì¥' in col_str:
            market_col = col
        elif 'ì—…ì¢…ëª…' in col_str or 'ì—…ì¢…' in col_str:
            sector_col = col
    
    # å¦‚æœè‡ªå‹•è­˜åˆ¥å¤±æ•—ï¼Œä½¿ç”¨å‰å¹¾åˆ—
    if not code_col and len(df.columns) > 0:
        code_col = df.columns[0]
    if not name_col and len(df.columns) > 1:
        name_col = df.columns[1]
    
    if not code_col or not name_col:
        log(f"âš ï¸ ç„¡æ³•è­˜åˆ¥å¿…è¦æ¬„ä½ï¼Œå¯ç”¨æ¬„ä½: {list(df.columns)}")
        return []
    
    stocks = []
    samples = []
    
    for idx, row in df.head(3000).iterrows():  # é™åˆ¶3000æ”¯é¿å…éå¤š
        try:
            # ç²å–è‚¡ç¥¨ä»£ç¢¼
            raw_code = str(row[code_col]).strip()
            code_6d = normalize_kr_code(raw_code)
            
            if not code_6d or code_6d == '000000':
                continue
            
            # ç²å–è‚¡ç¥¨åç¨±
            name = str(row[name_col]).strip() if name_col else f"KR_{code_6d}"
            
            # ç²å–å¸‚å ´ä¿¡æ¯
            market = "Unknown"
            if market_col and market_col in row:
                market_val = str(row[market_col]).strip().upper()
                if 'KOSPI' in market_val:
                    market = 'KOSPI'
                elif 'KOSDAQ' in market_val:
                    market = 'KOSDAQ'
                else:
                    market = market_val
            
            # ç²å–ç”¢æ¥­åˆ†é¡
            sector = "Other"
            if sector_col and sector_col in row:
                sector = str(row[sector_col]).strip()
                if pd.isna(sector) or sector == 'nan':
                    sector = "Other"
            
            # æ±ºå®šå¾Œç¶´
            suffix = ".KS" if market == "KOSPI" else ".KQ"
            symbol = f"{code_6d}{suffix}"
            
            stocks.append({
                'symbol': symbol,
                'name': name,
                'code_6d': code_6d,
                'market': market,
                'sector': sector,
                'raw_data': row.to_dict() if hasattr(row, 'to_dict') else {}
            })
            
            if len(samples) < 5:
                samples.append(f"   âœ“ {symbol} | {name[:12]:<12} | {market} | {sector[:15]}")
                
        except Exception as e:
            if idx < 5:  # åªé¡¯ç¤ºå‰å¹¾å€‹éŒ¯èª¤
                log(f"  è§£æç¬¬{idx}è¡Œæ™‚å‡ºéŒ¯: {e}")
            continue
    
    if samples:
        log("ğŸ” æ•¸æ“šæ¨£æœ¬:")
        for sample in samples:
            log(sample)
    
    return stocks

def get_kr_stock_list():
    """ä¸»å‡½æ•¸ï¼šç²å–éŸ“åœ‹è‚¡ç¥¨æ¸…å–®"""
    log("ğŸ“¡ æ­£åœ¨å¾ KRX ç²å–æœ€æ–°è‚¡ç¥¨æ¸…å–®...")
    
    # å˜—è©¦ä¸»è¦API
    df = fetch_krx_list_primary()
    
    # å¦‚æœä¸»è¦APIå¤±æ•—ï¼Œä½¿ç”¨å‚™ç”¨åˆ—è¡¨
    if df is None:
        log("âš ï¸ KRX API å¤±æ•—ï¼Œä½¿ç”¨å‚™ç”¨æ¸…å–®")
        df = fetch_fallback_list()
    
    # è§£ææ•¸æ“š
    stocks = parse_krx_data(df)
    
    if not stocks:
        log("âŒ ç„¡æ³•ç²å–ä»»ä½•è‚¡ç¥¨æ•¸æ“š")
        return []
    
    # å¯«å…¥æ•¸æ“šåº«
    conn = sqlite3.connect(DB_PATH)
    try:
        for stock in stocks:
            conn.execute("""
                INSERT OR REPLACE INTO stock_info 
                (symbol, name, sector, market, updated_at) 
                VALUES (?, ?, ?, ?, ?)
            """, (
                stock['symbol'], 
                stock['name'], 
                stock['sector'], 
                stock['market'], 
                datetime.now().strftime("%Y-%m-%d")
            ))
        conn.commit()
        log(f"âœ… éŸ“åœ‹æ¸…å–®å°å…¥æˆåŠŸ: {len(stocks)} æª”")
        
    except Exception as e:
        log(f"âŒ å¯«å…¥æ•¸æ“šåº«å¤±æ•—: {e}")
        conn.rollback()
    finally:
        conn.close()
    
    # è¿”å›çµ¦ä¸‹è¼‰æµç¨‹çš„æ ¼å¼
    return [(stock['symbol'], stock['name']) for stock in stocks]

# ========== 3. å„ªåŒ–çš„æ‰¹é‡ä¸‹è¼‰é‚è¼¯ ==========

def safe_yfinance_download(symbols, start_date, max_retries=2):
    """å®‰å…¨çš„yfinanceæ‰¹é‡ä¸‹è¼‰ï¼Œå¸¶é‡è©¦æ©Ÿåˆ¶"""
    for attempt in range(max_retries):
        try:
            # é©ç•¶å»¶é²é¿å…è¢«é™åˆ¶
            if attempt > 0:
                delay = 2 + random.uniform(0, 2)
                time.sleep(delay)
            
            data = yf.download(
                tickers=symbols,
                start=start_date,
                group_by='ticker',
                auto_adjust=True,
                threads=False,
                progress=False,
                timeout=30 + attempt * 10
            )
            
            return data
        except Exception as e:
            if attempt == max_retries - 1:
                log(f"âŒ ä¸‹è¼‰å¤±æ•— ({symbols[0] if symbols else 'N/A'}): {str(e)[:80]}")
            continue
    
    return None

def download_batch(batch_items, mode):
    """ä¸‹è¼‰ä¸€æ‰¹è‚¡ç¥¨æ•¸æ“š"""
    symbols = [item[0] for item in batch_items]
    start_date = "2020-01-01" if mode == 'hot' else "2010-01-01"
    
    if not symbols:
        return 0
    
    log(f"  æ‰¹æ¬¡ä¸‹è¼‰ {len(symbols)} æª”: {symbols[0]}..{symbols[-1] if len(symbols)>1 else ''}")
    
    data = safe_yfinance_download(symbols, start_date)
    if data is None or data.empty:
        return 0
    
    conn = sqlite3.connect(DB_PATH, timeout=60)
    success_count = 0
    
    try:
        # è™•ç†å–®ä¸€è‚¡ç¥¨æˆ–å¤šè‚¡ç¥¨çš„æƒ…æ³
        is_multi_symbol = len(symbols) > 1
        
        for symbol in symbols:
            try:
                # æå–è©²è‚¡ç¥¨çš„æ•¸æ“š
                if is_multi_symbol and symbol in data.columns.get_level_values(0):
                    df_symbol = data[symbol].copy()
                elif not is_multi_symbol:
                    df_symbol = data.copy()
                else:
                    continue  # è‚¡ç¥¨ä¸åœ¨ä¸‹è¼‰çš„æ•¸æ“šä¸­
                
                # æ¸…ç†æ•¸æ“š
                df_symbol = df_symbol.dropna(how='all')
                if df_symbol.empty:
                    continue
                
                # é‡ç½®ç´¢å¼•ä¸¦æ¨™æº–åŒ–
                df_symbol = df_symbol.reset_index()
                df_symbol.columns = [col.lower().replace(' ', '_') for col in df_symbol.columns]
                
                # è­˜åˆ¥æ—¥æœŸæ¬„ä½
                date_col = None
                for col in df_symbol.columns:
                    if 'date' in col.lower() or col.lower() == 'index':
                        date_col = col
                        break
                
                if not date_col:
                    continue
                
                # æº–å‚™æ’å…¥æ•¸æ“š
                rows_to_insert = []
                for _, row in df_symbol.iterrows():
                    try:
                        date_val = row[date_col]
                        if pd.isna(date_val):
                            continue
                        
                        # è½‰æ›æ—¥æœŸæ ¼å¼
                        if hasattr(date_val, 'strftime'):
                            date_str = date_val.strftime('%Y-%m-%d')
                        else:
                            date_str = pd.to_datetime(date_val).strftime('%Y-%m-%d')
                        
                        rows_to_insert.append((
                            date_str,
                            symbol,
                            float(row.get('open', 0)) if not pd.isna(row.get('open')) else 0,
                            float(row.get('high', 0)) if not pd.isna(row.get('high')) else 0,
                            float(row.get('low', 0)) if not pd.isna(row.get('low')) else 0,
                            float(row.get('close', 0)) if not pd.isna(row.get('close')) else 0,
                            int(row.get('volume', 0)) if not pd.isna(row.get('volume')) else 0
                        ))
                    except Exception:
                        continue
                
                if rows_to_insert:
                    # æ‰¹é‡æ’å…¥
                    conn.executemany(
                        "INSERT OR REPLACE INTO stock_prices VALUES (?,?,?,?,?,?,?)",
                        rows_to_insert
                    )
                    success_count += 1
                    
            except Exception as e:
                if random.random() < 0.1:  # åªè¨˜éŒ„10%çš„éŒ¯èª¤é¿å…æ—¥èªŒéå¤š
                    log(f"   è™•ç† {symbol} æ™‚å‡ºéŒ¯: {str(e)[:50]}")
                continue
        
        conn.commit()
        
    except Exception as e:
        log(f"âŒ æ‰¹æ¬¡è™•ç†å¤±æ•—: {e}")
        conn.rollback()
    finally:
        conn.close()
    
    return success_count

def run_sync(mode='hot'):
    """ä¸»åŒæ­¥å‡½æ•¸"""
    start_time = time.time()
    init_db()
    
    # ç²å–è‚¡ç¥¨æ¸…å–®
    items = get_kr_stock_list()
    if not items:
        log("âŒ ç„¡æ³•ç²å–è‚¡ç¥¨æ¸…å–®ï¼Œä½¿ç”¨æœ€å°å‚™ç”¨é›†")
        # æ¥µå°å‚™ç”¨é›†ï¼Œç¢ºä¿è‡³å°‘æœ‰æ•¸æ“š
        items = [("005930.KS", "Samsung Electronics"), ("000660.KS", "SK Hynix")]
    
    log(f"ğŸ“Š ç²å–åˆ° {len(items)} æª”éŸ“åœ‹è‚¡ç¥¨")
    
    # åˆ†æ‰¹è™•ç†
    batches = [items[i:i + BATCH_SIZE] for i in range(0, len(items), BATCH_SIZE)]
    log(f"ğŸš€ é–‹å§‹éŸ“è‚¡åŒæ­¥ | æ‰¹æ¬¡: {len(batches)} | æ¯æ‰¹: {BATCH_SIZE}æª”")
    
    total_success = 0
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        future_to_batch = {
            executor.submit(download_batch, batch, mode): batch 
            for batch in batches
        }
        
        pbar = tqdm(total=len(items), desc="KRåŒæ­¥", unit="æª”")
        
        for future in as_completed(future_to_batch):
            batch = future_to_batch[future]
            try:
                success_in_batch = future.result()
                total_success += success_in_batch
                log(f"  æ‰¹æ¬¡å®Œæˆ: {success_in_batch}/{len(batch)} æˆåŠŸ")
            except Exception as e:
                log(f"  æ‰¹æ¬¡ç•°å¸¸: {e}")
            
            # æ‰¹æ¬¡é–“å»¶é²
            time.sleep(random.uniform(*BATCH_DELAY))
            pbar.update(len(batch))
        
        pbar.close()
    
    # æ•¸æ“šåº«å„ªåŒ–
    log("ğŸ§¹ å„ªåŒ–æ•¸æ“šåº«...")
    conn = sqlite3.connect(DB_PATH)
    conn.execute("VACUUM")
    
    # çµ±è¨ˆä¿¡æ¯
    cursor = conn.execute("SELECT COUNT(DISTINCT symbol) FROM stock_prices")
    unique_symbols = cursor.fetchone()[0]
    
    cursor = conn.execute("SELECT COUNT(*) FROM stock_info")
    total_listed = cursor.fetchone()[0]
    
    conn.close()
    
    duration = (time.time() - start_time) / 60
    
    # è¨ˆç®—è¦†è“‹ç‡ï¼ˆé¿å…é™¤ä»¥é›¶ï¼‰
    coverage = 0
    if total_listed > 0:
        coverage = (unique_symbols / total_listed * 100)
    
    log(f"ğŸ“Š åŒæ­¥å®Œæˆï¼è€—æ™‚: {duration:.1f}åˆ†é˜")
    log(f"âœ… æˆåŠŸä¸‹è¼‰: {total_success}/{len(items)} æª”")
    log(f"ğŸ“ˆ æ•¸æ“šåº«çµ±è¨ˆ: {unique_symbols} æª”æœ‰åƒ¹æ ¼æ•¸æ“š / {total_listed} æª”åœ¨æ¸…å–®ä¸­")
    log(f"ğŸ¯ è¦†è“‹ç‡: {coverage:.1f}%")
    
    return {
        "success": total_success,
        "total": len(items),
        "has_changed": total_success > 0,
        "coverage": f"{coverage:.1f}%",
        "duration_minutes": f"{duration:.1f}"
    }

# ========== 4. ç›´æ¥åŸ·è¡Œæ¸¬è©¦ ==========
if __name__ == "__main__":
    log("=" * 50)
    log("ğŸŸ¢ éŸ“åœ‹è‚¡ç¥¨ä¸‹è¼‰å™¨å•Ÿå‹•")
    log("=" * 50)
    
    result = run_sync(mode='hot')
    
    log("=" * 50)
    log("ğŸ æœ€çµ‚çµæœ")
    log(f"   æˆåŠŸ: {result['success']}/{result['total']}")
    log(f"   è¦†è“‹ç‡: {result['coverage']}")
    log(f"   è€—æ™‚: {result['duration_minutes']}åˆ†é˜")
    log("=" * 50)
