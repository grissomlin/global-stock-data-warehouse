# -*- coding: utf-8 -*-
import os, sys, time, random, subprocess, sqlite3, json
import pandas as pd
import yfinance as yf
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed
from tqdm import tqdm

# ========== æ ¸å¿ƒåƒæ•¸è¨­å®š ==========
MARKET_CODE = "kr-share"
DATA_SUBDIR = "dayK"
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
# è³‡æ–™èˆ‡å¯©è¨ˆè³‡æ–™åº«è·¯å¾‘
DATA_DIR = os.path.join(BASE_DIR, "data", MARKET_CODE, DATA_SUBDIR)
AUDIT_DB_PATH = os.path.join(BASE_DIR, "data_warehouse_audit.db")

# âœ… æ•ˆèƒ½èˆ‡æ™‚æ•ˆè¨­å®š
MAX_WORKERS = 3 
DATA_EXPIRY_SECONDS = 3600  # 1 å°æ™‚å…§æŠ“éå‰‡è·³é

os.makedirs(DATA_DIR, exist_ok=True)

def log(msg: str):
    print(f"{pd.Timestamp.now():%H:%M:%S}: {msg}")

def ensure_pkg(pkg: str):
    """ç¢ºä¿å¿…è¦å¥—ä»¶å·²å®‰è£"""
    try:
        __import__(pkg)
    except ImportError:
        log(f"ğŸ”§ æ­£åœ¨å®‰è£ {pkg}...")
        subprocess.run([sys.executable, "-m", "pip", "install", "-q", pkg])

def init_audit_db():
    """åˆå§‹åŒ–å¯©è¨ˆè³‡æ–™åº«"""
    conn = sqlite3.connect(AUDIT_DB_PATH)
    conn.execute('''CREATE TABLE IF NOT EXISTS sync_audit (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        execution_time TEXT,
        market_id TEXT,
        total_count INTEGER,
        success_count INTEGER,
        fail_count INTEGER,
        success_rate REAL
    )''')
    conn.close()

def get_full_stock_list():
    """ç²å–éŸ“è‚¡å®Œæ•´æ¸…å–® (KOSPI & KOSDAQ)"""
    # ä½¿ç”¨ FinanceDataReader ç²å–æ¸…å–®ï¼Œé€™æ¯”æ‰‹å‹•çˆ¬ç¶²é ç©©å®š
    ensure_pkg("finance-datareader")
    import FinanceDataReader as fdr
    
    print("ğŸ“¡ æ­£åœ¨ç²å–éŸ“åœ‹å¸‚å ´ (KOSPI/KOSDAQ) å®Œæ•´æ¸…å–®...")
    try:
        df_kospi = fdr.StockListing('KOSPI')
        df_kosdaq = fdr.StockListing('KOSDAQ')
        df = pd.concat([df_kospi, df_kosdaq])
        
        # Yahoo Finance æ ¼å¼ï¼šKOSPI ç‚º .KS, KOSDAQ ç‚º .KQ
        res = []
        for _, row in df.iterrows():
            code = str(row['Code']).strip()
            # åˆ¤æ–·å¸‚å ´å¾Œç¶´
            suffix = ".KS" if row['Market'] == 'KOSPI' else ".KQ"
            res.append(f"{code}{suffix}")
        
        final_list = list(set(res))
        print(f"âœ… æˆåŠŸç²å– {len(final_list)} æª”éŸ“è‚¡ä»£è™Ÿ")
        return final_list
    except Exception as e:
        print(f"âŒ éŸ“è‚¡æ¸…å–®ç²å–å¤±æ•—: {e}")
        return ["005930.KS", "000660.KS"] # ä¸‰æ˜Ÿé›»å­ & SKæµ·åŠ›å£«ä¿åº•

def download_one(symbol, period):
    """å–®æª”ä¸‹è¼‰é‚è¼¯ï¼šæ™ºæ…§å¿«å– + é‡è©¦"""
    out_path = os.path.join(DATA_DIR, f"{symbol}.csv")
    
    # ğŸ’¡ æ™ºæ…§å¿«å–æª¢æŸ¥ (æŠ“éä¸”åœ¨æ•ˆæœŸå…§å‰‡è·³é)
    if os.path.exists(out_path):
        file_age = time.time() - os.path.getmtime(out_path)
        if file_age < DATA_EXPIRY_SECONDS and os.path.getsize(out_path) > 1000:
            return {"status": "exists", "tkr": symbol}

    try:
        time.sleep(random.uniform(0.6, 1.2))
        tk = yf.Ticker(symbol)
        hist = tk.history(period=period, timeout=30)
        
        if hist is not None and not hist.empty:
            hist = hist.reset_index()
            hist.columns = [c.lower() for c in hist.columns]
            if 'date' in hist.columns:
                hist['date'] = pd.to_datetime(hist['date'], utc=True).dt.tz_localize(None).dt.strftime('%Y-%m-%d')
                hist['symbol'] = symbol
                # éæ¿¾ä¸¦å„²å­˜æ¨™æº–æ¬„ä½
                hist[['date', 'symbol', 'open', 'high', 'low', 'close', 'volume']].to_csv(out_path, index=False, encoding='utf-8-sig')
                return {"status": "success", "tkr": symbol}
        return {"status": "empty", "tkr": symbol}
    except:
        return {"status": "error", "tkr": symbol}

def main():
    """ä¸»é€²å…¥é»ï¼šå°æ¥ main.py é‚è¼¯"""
    start_time = time.time()
    init_audit_db()
    
    # åˆ¤æ–·æ˜¯å¦ç‚ºåˆæ¬¡æŠ“å–ï¼Œå¯ç”± main.py å‘¼å«æ™‚æ±ºå®šï¼Œé€™è£¡é è¨­ç‚º 7d
    is_first_time = False 
    period = "max" if is_first_time else "7d"
    
    items = get_full_stock_list()
    log(f"ğŸš€ éŸ“è‚¡ä»»å‹™å•Ÿå‹•: {period}, ç›®æ¨™ç¸½æ•¸: {len(items)} æª”")
    
    stats = {"success": 0, "exists": 0, "empty": 0, "error": 0}
    fail_list = []

    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        futures = {executor.submit(download_one, tkr, period): tkr for tkr in items}
        pbar = tqdm(total=len(items), desc="KR ä¸‹è¼‰é€²åº¦")
        
        for future in as_completed(futures):
            res = future.result()
            s = res.get("status", "error")
            stats[s] += 1
            if s in ["error", "empty"]:
                fail_list.append(res.get("tkr", "Unknown"))
            pbar.update(1)
        pbar.close()

    total = len(items)
    success = stats['success'] + stats['exists']
    fail = stats['error'] + stats['empty']
    rate = round((success / total * 100), 2) if total > 0 else 0

    # ğŸš€ ç´€éŒ„ Audit DB (å°åŒ—æ™‚é–“ UTC+8)
    conn = sqlite3.connect(AUDIT_DB_PATH)
    try:
        now_ts = (datetime.utcnow() + pd.Timedelta(hours=8)).strftime("%Y-%m-%d %H:%M:%S")
        conn.execute('''INSERT INTO sync_audit 
            (execution_time, market_id, total_count, success_count, fail_count, success_rate)
            VALUES (?, ?, ?, ?, ?, ?)''', (now_ts, MARKET_CODE, total, success, fail, rate))
        conn.commit()
    finally:
        conn.close()

    # å›å‚³çµ±è¨ˆå­—å…¸
    download_stats = {
        "total": total,
        "success": success,
        "fail": fail,
        "fail_list": fail_list
    }

    log(f"ğŸ“Š éŸ“è‚¡åŸ·è¡Œå ±å‘Š: æˆåŠŸ={success}, å¤±æ•—={fail}, æˆåŠŸç‡={rate}%")
    return download_stats

if __name__ == "__main__":
    main()
