# -*- coding: utf-8 -*-
import os, io, time, random, sqlite3, requests
import pandas as pd
import yfinance as yf
from io import StringIO
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed
from tqdm import tqdm

# ========== 1. ç’°å¢ƒåˆ¤æ–·èˆ‡åƒæ•¸è¨­å®š ==========
MARKET_CODE = "tw-share"
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DB_PATH = os.path.join(BASE_DIR, "tw_stock_warehouse.db")
IS_GITHUB_ACTIONS = os.getenv('GITHUB_ACTIONS') == 'true'

CACHE_DIR = os.path.join(BASE_DIR, "cache_tw")
DATA_EXPIRY_SECONDS = 86400

if not IS_GITHUB_ACTIONS and not os.path.exists(CACHE_DIR):
    os.makedirs(CACHE_DIR, exist_ok=True)

# âœ… æ•ˆèƒ½èª¿å„ªï¼šå°è‚¡å°é€£ç·šæ¥µå…¶æ•æ„Ÿï¼ŒGitHub æ¨¡å¼é™è‡³ 2~3 åŸ·è¡Œç·’
MAX_WORKERS = 3 if IS_GITHUB_ACTIONS else 4 

def log(msg: str):
    print(f"{pd.Timestamp.now():%H:%M:%S}: {msg}")

# ========== 2. æ ¸å¿ƒè¼”åŠ©å‡½å¼ ==========

def insert_or_replace(table, conn, keys, data_iter):
    sql = f"INSERT OR REPLACE INTO {table.name} ({', '.join(keys)}) VALUES ({', '.join(['?']*len(keys))})"
    conn.executemany(sql, data_iter)

def init_db():
    """åˆå§‹åŒ–è³‡æ–™åº«çµæ§‹ (ç¢ºä¿åŒ…å« market æ¬„ä½)"""
    conn = sqlite3.connect(DB_PATH)
    try:
        conn.execute('''CREATE TABLE IF NOT EXISTS stock_prices (
                            date TEXT, symbol TEXT, open REAL, high REAL, 
                            low REAL, close REAL, volume INTEGER,
                            PRIMARY KEY (date, symbol))''')
        # ğŸ’¡ ç¢ºä¿æœ‰ name, sector, market ä¸‰å¤§è³‡è¨Šæ¬„ä½
        conn.execute('''CREATE TABLE IF NOT EXISTS stock_info (
                            symbol TEXT PRIMARY KEY, 
                            name TEXT, 
                            sector TEXT, 
                            market TEXT, 
                            updated_at TEXT)''')
        conn.commit()
    finally:
        conn.close()

def get_tw_stock_list():
    """å¾è­‰äº¤æ‰€ç²å–åŒ…å«å¸‚å ´åˆ¥èˆ‡ç”¢æ¥­åˆ¥çš„å®Œæ•´æ¸…å–®"""
    market_map = {
        'listed': 'ä¸Šå¸‚',
        'otc': 'ä¸Šæ«ƒ',
        'etf': 'ETF',
        'rotc': 'èˆˆæ«ƒ',
        'tw_innovation': 'å‰µæ–°æ¿',
        'otc_innovation': 'æˆ°ç•¥æ–°æ¿',
        'dr': 'å­˜è¨—æ†‘è­‰'
    }

    url_configs = [
        {'name': 'listed', 'url': 'https://isin.twse.com.tw/isin/class_main.jsp?market=1&issuetype=1&Page=1&chklike=Y', 'suffix': '.TW'},
        {'name': 'otc', 'url': 'https://isin.twse.com.tw/isin/class_main.jsp?market=2&issuetype=4&Page=1&chklike=Y', 'suffix': '.TWO'},
        {'name': 'etf', 'url': 'https://isin.twse.com.tw/isin/class_main.jsp?owncode=&stockname=&isincode=&market=1&issuetype=I&industry_code=&Page=1&chklike=Y', 'suffix': '.TW'},
        {'name': 'rotc', 'url': 'https://isin.twse.com.tw/isin/class_main.jsp?owncode=&stockname=&isincode=&market=E&issuetype=R&industry_code=&Page=1&chklike=Y', 'suffix': '.TWO'},
        {'name': 'tw_innovation', 'url': 'https://isin.twse.com.tw/isin/class_main.jsp?owncode=&stockname=&isincode=&market=C&issuetype=C&industry_code=&Page=1&chklike=Y', 'suffix': '.TW'},
        {'name': 'otc_innovation', 'url': 'https://isin.twse.com.tw/isin/class_main.jsp?owncode=&stockname=&isincode=&market=A&issuetype=C&industry_code=&Page=1&chklike=Y', 'suffix': '.TWO'},
        {'name': 'dr', 'url': 'https://isin.twse.com.tw/isin/class_main.jsp?owncode=&stockname=&isincode=&market=1&issuetype=J&industry_code=&Page=1&chklike=Y', 'suffix': '.TW'},
    ]

    log(f"ğŸ“¡ æ­£åœ¨åŒæ­¥å°è‚¡æ¸…å–® (å«ç”¢æ¥­èˆ‡å¸‚å ´åˆ¥)...")
    conn = sqlite3.connect(DB_PATH)
    stock_list = []

    for cfg in url_configs:
        try:
            time.sleep(random.uniform(0.5, 1.0))
            resp = requests.get(cfg['url'], timeout=15)
            # è®€å–ç¶²é è¡¨æ ¼
            df = pd.read_html(StringIO(resp.text), header=0)[0]

            for _, row in df.iterrows():
                code = str(row['æœ‰åƒ¹è­‰åˆ¸ä»£è™Ÿ']).strip()
                name = str(row['æœ‰åƒ¹è­‰åˆ¸åç¨±']).strip()
                sector = str(row.get('ç”¢æ¥­åˆ¥', 'Unknown')).strip()
                market_label = market_map.get(cfg['name'], 'å…¶ä»–')

                if code.isalnum() and len(code) >= 4:
                    symbol = f"{code}{cfg['suffix']}"
                    # ğŸ’¡ å­˜å…¥è³‡æ–™åº«æ™‚åŒ…å«è©³ç´°è³‡è¨Š
                    conn.execute("""
                        INSERT OR REPLACE INTO stock_info (symbol, name, sector, market, updated_at) 
                        VALUES (?, ?, ?, ?, ?)
                    """, (symbol, name, sector, market_label, datetime.now().strftime("%Y-%m-%d")))
                    stock_list.append((symbol, name))
        except Exception as e:
            log(f"âš ï¸ æŠ“å– {cfg['name']} å¸‚å ´å¤±æ•—: {e}")

    conn.commit()
    conn.close()
    
    unique_items = list(dict.fromkeys(stock_list))
    log(f"âœ… å°è‚¡æ¸…å–®åŒæ­¥å®Œæˆï¼Œæ¨™çš„ç¸½æ•¸: {len(unique_items)} æª”")
    return unique_items

# ========== 3. æ ¸å¿ƒä¸‹è¼‰/é‡è©¦é‚è¼¯ ==========

def download_one(args):
    symbol, name, mode = args
    csv_path = os.path.abspath(os.path.join(CACHE_DIR, f"{symbol}.csv"))
    start_date = "2020-01-01" if mode == 'hot' else "1993-01-04"
    
    if not IS_GITHUB_ACTIONS and os.path.exists(csv_path):
        file_age = time.time() - os.path.getmtime(csv_path)
        if file_age < DATA_EXPIRY_SECONDS:
            return {"symbol": symbol, "status": "cache"}

    # ğŸ’¡ å¢åŠ é‡è©¦æ©Ÿåˆ¶èˆ‡é•·å»¶é²
    max_retries = 3
    for attempt in range(max_retries):
        try:
            wait_time = random.uniform(1.5, 3.2) if IS_GITHUB_ACTIONS else random.uniform(0.2, 0.5)
            time.sleep(wait_time)
            
            tk = yf.Ticker(symbol)
            hist = tk.history(start=start_date, timeout=25, auto_adjust=True)
            
            if hist is None or hist.empty:
                return {"symbol": symbol, "status": "empty"}
                
            hist.reset_index(inplace=True)
            hist.columns = [c.lower() for c in hist.columns]
            if 'date' in hist.columns:
                hist['date'] = pd.to_datetime(hist['date']).dt.tz_localize(None).dt.strftime('%Y-%m-%d')
            
            df_final = hist[['date', 'open', 'high', 'low', 'close', 'volume']].copy()
            df_final['symbol'] = symbol
            
            if not IS_GITHUB_ACTIONS:
                df_final.to_csv(csv_path, index=False)

            conn = sqlite3.connect(DB_PATH, timeout=60)
            df_final.to_sql('stock_prices', conn, if_exists='append', index=False, method=insert_or_replace)
            conn.close()
            
            return {"symbol": symbol, "status": "success"}
        except Exception:
            if attempt < max_retries - 1:
                time.sleep(random.uniform(5, 12))
                continue
            return {"symbol": symbol, "status": "error"}

# ========== 4. ä¸»æµç¨‹ ==========

def run_sync(mode='hot'):
    start_time = time.time()
    init_db()
    
    items = get_tw_stock_list()
    if not items:
        log("âŒ ç„¡æ³•å–å¾—æ¸…å–®ï¼Œä»»å‹™çµ‚æ­¢ã€‚")
        return {"fail_list": [], "success": 0, "has_changed": False}

    log(f"ğŸš€ é–‹å§‹åŸ·è¡Œå°è‚¡åŒæ­¥ ({mode.upper()}) | ç›®æ¨™: {len(items)} æª”")

    stats = {"success": 0, "cache": 0, "empty": 0, "error": 0}
    fail_list = []
    task_args = [(it[0], it[1], mode) for it in items]
    
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        futures = {executor.submit(download_one, arg): arg for arg in task_args}
        pbar = tqdm(total=len(items), desc=f"TWè™•ç†ä¸­({mode})")
        
        for f in as_completed(futures):
            res = f.result()
            s = res.get("status", "error")
            stats[s] += 1
            if s == "error":
                fail_list.append(res.get("symbol"))
            pbar.update(1)
        pbar.close()

    has_changed = stats['success'] > 0
    if has_changed or IS_GITHUB_ACTIONS:
        log("ğŸ§¹ åŸ·è¡Œè³‡æ–™åº«å„ªåŒ– (VACUUM)...")
        conn = sqlite3.sqlite3.connect(DB_PATH)
        conn.execute("VACUUM")
        conn.close()

    duration = (time.time() - start_time) / 60
    log(f"ğŸ“Š åŒæ­¥å®Œæˆï¼è²»æ™‚: {duration:.1f} åˆ†é˜")
    
    return {
        "success": stats['success'],
        "cache": stats['cache'],
        "error": stats['error'],
        "total": len(items),
        "fail_list": fail_list,
        "has_changed": has_changed
    }

if __name__ == "__main__":
    run_sync(mode='hot')
