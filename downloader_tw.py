# -*- coding: utf-8 -*-
import os, io, time, random, sqlite3, requests, re
import pandas as pd
import yfinance as yf
from io import StringIO
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed
from tqdm import tqdm

# ========== 1. ç’°å¢ƒåˆ¤æ–·èˆ‡åƒæ•¸è¨­å®š ==========
MARKET_CODE = "tw-share"
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DB_PATH = os.path.join(BASE_DIR, "tw_stock_warehouse.db")
IS_GITHUB_ACTIONS = os.getenv('GITHUB_ACTIONS') == 'true'

CACHE_DIR = os.path.join(BASE_DIR, "cache_tw")
DATA_EXPIRY_SECONDS = 86400

if not IS_GITHUB_ACTIONS and not os.path.exists(CACHE_DIR):
    os.makedirs(CACHE_DIR, exist_ok=True)

# âœ… æ•ˆèƒ½å„ªåŒ–è¨­å®šï¼šGitHub æ¨¡å¼ 6 åŸ·è¡Œç·’ï¼ŒLocal 10 åŸ·è¡Œç·’
MAX_WORKERS = 6 if IS_GITHUB_ACTIONS else 10 

def log(msg: str):
    print(f"{pd.Timestamp.now():%H:%M:%S}: {msg}")

# ========== 2. è³‡æ–™åº«åˆå§‹åŒ–èˆ‡çµæ§‹ç¶­è­· ==========

def init_db():
    """åˆå§‹åŒ–ä¸¦è‡ªå‹•å‡ç´šè³‡æ–™åº«çµæ§‹"""
    conn = sqlite3.connect(DB_PATH)
    try:
        # å»ºç«‹åƒ¹æ ¼è¡¨
        conn.execute('''CREATE TABLE IF NOT EXISTS stock_prices (
                            date TEXT, symbol TEXT, open REAL, high REAL, 
                            low REAL, close REAL, volume INTEGER,
                            PRIMARY KEY (date, symbol))''')
        # å»ºç«‹è³‡è¨Šè¡¨
        conn.execute('''CREATE TABLE IF NOT EXISTS stock_info (
                            symbol TEXT PRIMARY KEY, name TEXT, sector TEXT, updated_at TEXT)''')
        
        # ğŸ’¡ è‡ªå‹•å‡ç´šï¼šæª¢æŸ¥ä¸¦æ–°å¢ç¼ºå¤±çš„ market æ¬„ä½
        cursor = conn.execute("PRAGMA table_info(stock_info)")
        columns = [column[1] for column in cursor.fetchall()]
        if 'market' not in columns:
            log("ğŸ”§ æ­£åœ¨å‡ç´šè³‡æ–™åº«ï¼šæ–°å¢ 'market' æ¬„ä½...")
            conn.execute("ALTER TABLE stock_info ADD COLUMN market TEXT")
            conn.commit()
    finally:
        conn.close()

def get_tw_stock_list():
    """å¾è­‰äº¤æ‰€ç²å–æ¸…å–®ä¸¦æ¨™è¨˜å¸‚å ´åˆ¥"""
    market_map = {
        'listed': 'ä¸Šå¸‚',
        'otc': 'ä¸Šæ«ƒ',
        'etf': 'ETF',
        'rotc': 'èˆˆæ«ƒ'
    }
    url_configs = [
        {'name': 'listed', 'url': 'https://isin.twse.com.tw/isin/class_main.jsp?market=1&issuetype=1&Page=1&chklike=Y', 'suffix': '.TW'},
        {'name': 'otc', 'url': 'https://isin.twse.com.tw/isin/class_main.jsp?market=2&issuetype=4&Page=1&chklike=Y', 'suffix': '.TWO'},
        {'name': 'etf', 'url': 'https://isin.twse.com.tw/isin/class_main.jsp?owncode=&stockname=&isincode=&market=1&issuetype=I&industry_code=&Page=1&chklike=Y', 'suffix': '.TW'},
        {'name': 'rotc', 'url': 'https://isin.twse.com.tw/isin/class_main.jsp?owncode=&stockname=&isincode=&market=E&issuetype=R&industry_code=&Page=1&chklike=Y', 'suffix': '.TWO'},
    ]
    
    log(f"ğŸ“¡ ç²å–å°è‚¡æ¸…å–®ä¸¦åŒæ­¥è³‡è¨Š...")
    conn = sqlite3.connect(DB_PATH)
    stock_list = []
    
    for cfg in url_configs:
        try:
            resp = requests.get(cfg['url'], timeout=15)
            df = pd.read_html(StringIO(resp.text), header=0)[0]
            market_label = market_map.get(cfg['name'], 'å…¶ä»–')
            
            for _, row in df.iterrows():
                code = str(row['æœ‰åƒ¹è­‰åˆ¸ä»£è™Ÿ']).strip()
                name = str(row['æœ‰åƒ¹è­‰åˆ¸åç¨±']).strip()
                sector = str(row.get('ç”¢æ¥­åˆ¥', 'Unknown')).strip()
                
                if code.isalnum() and len(code) >= 4:
                    symbol = f"{code}{cfg['suffix']}"
                    # ğŸ’¡ å¯«å…¥åŒ…å«å¸‚å ´åˆ¥çš„å®Œæ•´è³‡è¨Š
                    conn.execute("""
                        INSERT OR REPLACE INTO stock_info (symbol, name, sector, market, updated_at) 
                        VALUES (?, ?, ?, ?, ?)
                    """, (symbol, name, sector, market_label, datetime.now().strftime("%Y-%m-%d")))
                    stock_list.append((symbol, name))
        except Exception as e:
            log(f"âš ï¸ ç²å– {cfg['name']} å¸‚å ´å¤±æ•—: {e}")
            
    conn.commit()
    conn.close()
    return list(set(stock_list))

# ========== 3. æ ¸å¿ƒä¸‹è¼‰é‚è¼¯ (å…·å‚™é‡è©¦æ©Ÿåˆ¶) ==========

def download_one(args):
    symbol, name, mode = args
    csv_path = os.path.abspath(os.path.join(CACHE_DIR, f"{symbol}.csv"))
    start_date = "2020-01-01" if mode == 'hot' else "1993-01-04"
    
    if not IS_GITHUB_ACTIONS and os.path.exists(csv_path):
        file_age = time.time() - os.path.getmtime(csv_path)
        if file_age < DATA_EXPIRY_SECONDS:
            return {"symbol": symbol, "status": "cache", "data": None}

    # ğŸ’¡ å¢åŠ é‡è©¦æ©Ÿåˆ¶ (æœ€å¤šå˜—è©¦ 3 æ¬¡)
    max_retries = 2
    for attempt in range(max_retries + 1):
        try:
            time.sleep(random.uniform(0.1, 0.3))
            tk = yf.Ticker(symbol)
            hist = tk.history(start=start_date, timeout=20, auto_adjust=True)
            
            if hist is None or hist.empty:
                if attempt < max_retries: continue
                return {"symbol": symbol, "status": "empty", "data": None}
            
            hist.reset_index(inplace=True)
            hist.columns = [c.lower() for c in hist.columns]
            
            # âœ… å£“å¹³ MultiIndex (è™•ç† yfinance éš¨æ©Ÿå‡ºç¾çš„é›™å±¤è¡¨é ­)
            if isinstance(hist.columns, pd.MultiIndex):
                hist.columns = hist.columns.get_level_values(0)

            hist['date'] = pd.to_datetime(hist['date']).dt.tz_localize(None).dt.strftime('%Y-%m-%d')
            df_final = hist[['date', 'open', 'high', 'low', 'close', 'volume']].copy()
            df_final['symbol'] = symbol
            
            if not IS_GITHUB_ACTIONS:
                df_final.to_csv(csv_path, index=False)
                
            return {"symbol": symbol, "status": "success", "data": df_final}
        except Exception:
            if attempt < max_retries:
                time.sleep(random.uniform(1.5, 3.0)) # éŒ¯èª¤å¾Œéš¨æ©Ÿç­‰å¾…ä¹…ä¸€é»å†é‡è©¦
                continue
            return {"symbol": symbol, "status": "error", "data": None}

# ========== 4. ä¸»æµç¨‹ (æ‰¹æ¬¡å¯«å…¥) ==========

def run_sync(mode='hot'):
    start_time = time.time()
    init_db()
    
    items = get_tw_stock_list()
    if not items:
        return {"fail_list": [], "success": 0, "has_changed": False}

    log(f"ğŸš€ é–‹å§‹åŒæ­¥ TW | ç›®æ¨™: {len(items)} æª” | åŸ·è¡Œç·’: {MAX_WORKERS}")

    stats = {"success": 0, "cache": 0, "empty": 0, "error": 0}
    fail_list = []
    
    # ğŸ’¡ ä½¿ç”¨å–®ä¸€é€£ç·šæ‰¹æ¬¡å¯«å…¥ï¼Œé¿å…é »ç¹ IO
    conn = sqlite3.connect(DB_PATH, timeout=60)
    
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        futures = {executor.submit(download_one, (it[0], it[1], mode)): it[0] for it in items}
        pbar = tqdm(total=len(items), desc=f"TWåŒæ­¥({mode})")
        
        for f in as_completed(futures):
            res = f.result()
            s = res.get("status")
            stats[s] += 1
            
            if s == "success" and res["data"] is not None:
                # å¯«å…¥åƒ¹æ ¼è³‡æ–™
                res["data"].to_sql('stock_prices', conn, if_exists='append', index=False, 
                                 method=lambda table, conn, keys, data_iter: 
                                 conn.executemany(f"INSERT OR REPLACE INTO {table.name} ({', '.join(keys)}) VALUES ({', '.join(['?']*len(keys))})", data_iter))
            
            if s in ["error", "empty"]:
                fail_list.append(res.get("symbol"))
            pbar.update(1)
            
        pbar.close()
    
    conn.commit()
    conn.close()

    # ğŸ’¡ ä¿®æ­£å›å‚³çµ±è¨ˆï¼šæŸ¥è©¢è³‡æ–™åº«ä¸­å¯¦éš›æ“æœ‰çš„ä¸é‡è¤‡æ¨™çš„ç¸½æ•¸
    conn = sqlite3.connect(DB_PATH)
    final_db_count = conn.execute("SELECT COUNT(DISTINCT symbol) FROM stock_info").fetchone()[0]
    conn.close()

    has_changed = stats['success'] > 0
    if has_changed or IS_GITHUB_ACTIONS:
        log("ğŸ§¹ å„ªåŒ–è³‡æ–™åº« (VACUUM)...")
        conn = sqlite3.connect(DB_PATH)
        conn.execute("VACUUM")
        conn.close()

    duration = (time.time() - start_time) / 60
    log(f"ğŸ“Š åŒæ­¥å®Œæˆï¼è²»æ™‚: {duration:.1f} åˆ†é˜")
    log(f"âœ… è³‡æ–™åº«ç¸½æ•¸: {final_db_count} | æœ¬æ¬¡æ›´æ–°: {stats['success']} | âŒ éŒ¯èª¤/ç„¡è³‡æ–™: {stats['error'] + stats['empty']}")

    return {
        "success": final_db_count,     # å›å‚³è³‡æ–™åº«å¯¦æœ‰ç¸½æ•¸ï¼Œé˜²æ­¢ Coverage çˆ†è¡¨
        "total": len(items),          # æœ¬æ¬¡ç›®æ¨™æ¸…å–®ç¸½æ•¸
        "fail_list": fail_list,
        "has_changed": has_changed
    }

if __name__ == "__main__":
    run_sync(mode='hot')
