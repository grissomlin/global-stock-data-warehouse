# -*- coding: utf-8 -*-
import os, io, time, random, sqlite3, requests, re
import pandas as pd
import yfinance as yf
from io import StringIO
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed
from tqdm import tqdm

# ========== 1. ç’°å¢ƒåˆ¤æ–·èˆ‡åƒæ•¸è¨­å®š ==========
MARKET_CODE = "tw-share"
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DB_PATH = os.path.join(BASE_DIR, "tw_stock_warehouse.db")
IS_GITHUB_ACTIONS = os.getenv('GITHUB_ACTIONS') == 'true'

CACHE_DIR = os.path.join(BASE_DIR, "cache_tw")
DATA_EXPIRY_SECONDS = 86400

if not IS_GITHUB_ACTIONS and not os.path.exists(CACHE_DIR):
    os.makedirs(CACHE_DIR, exist_ok=True)

# âœ… æ•ˆèƒ½å„ªåŒ–è¨­å®š
# GitHub æ¨¡å¼ä¸‹ç¨å¾®æå‡åŸ·è¡Œç·’åˆ° 6ï¼ŒLocal ç¶­æŒ 8-10
MAX_WORKERS = 6 if IS_GITHUB_ACTIONS else 10 

def log(msg: str):
    print(f"{pd.Timestamp.now():%H:%M:%S}: {msg}")

# ========== 2. æ ¸å¿ƒè¼”åŠ©å‡½å¼ ==========

def init_db():
    conn = sqlite3.connect(DB_PATH)
    try:
        conn.execute('''CREATE TABLE IF NOT EXISTS stock_prices (
                            date TEXT, symbol TEXT, open REAL, high REAL, 
                            low REAL, close REAL, volume INTEGER,
                            PRIMARY KEY (date, symbol))''')
        conn.execute('''CREATE TABLE IF NOT EXISTS stock_info (
                            symbol TEXT PRIMARY KEY, name TEXT, sector TEXT, updated_at TEXT)''')
        conn.commit()
    finally:
        conn.close()

def get_tw_stock_list():
    url_configs = [
        {'name': 'listed', 'url': 'https://isin.twse.com.tw/isin/class_main.jsp?market=1&issuetype=1&Page=1&chklike=Y', 'suffix': '.TW'},
        {'name': 'otc', 'url': 'https://isin.twse.com.tw/isin/class_main.jsp?market=2&issuetype=4&Page=1&chklike=Y', 'suffix': '.TWO'},
        {'name': 'etf', 'url': 'https://isin.twse.com.tw/isin/class_main.jsp?owncode=&stockname=&isincode=&market=1&issuetype=I&industry_code=&Page=1&chklike=Y', 'suffix': '.TW'},
        {'name': 'rotc', 'url': 'https://isin.twse.com.tw/isin/class_main.jsp?owncode=&stockname=&isincode=&market=E&issuetype=R&industry_code=&Page=1&chklike=Y', 'suffix': '.TWO'},
    ]
    
    log(f"ğŸ“¡ ç²å–å°è‚¡æ¸…å–®...")
    conn = sqlite3.connect(DB_PATH)
    stock_list = []
    
    for cfg in url_configs:
        try:
            resp = requests.get(cfg['url'], timeout=15)
            df_list = pd.read_html(StringIO(resp.text), header=0)
            if not df_list: continue
            df = df_list[0]
            
            for _, row in df.iterrows():
                code = str(row['æœ‰åƒ¹è­‰åˆ¸ä»£è™Ÿ']).strip()
                name = str(row['æœ‰åƒ¹è­‰åˆ¸åç¨±']).strip()
                sector = str(row.get('ç”¢æ¥­åˆ¥', 'Unknown')).strip()
                
                if code.isalnum() and len(code) >= 4:
                    symbol = f"{code}{cfg['suffix']}"
                    conn.execute("INSERT OR REPLACE INTO stock_info (symbol, name, sector, updated_at) VALUES (?, ?, ?, ?)",
                                 (symbol, name, sector, datetime.now().strftime("%Y-%m-%d")))
                    stock_list.append((symbol, name))
        except Exception as e:
            log(f"âš ï¸ ç²å– {cfg['name']} å¸‚å ´å¤±æ•—: {e}")
            
    conn.commit()
    conn.close()
    unique_items = list(set(stock_list))
    log(f"âœ… å°è‚¡æ¸…å–®å®Œæˆï¼Œæ¨™çš„: {len(unique_items)} æª”")
    return unique_items

# ========== 3. æ ¸å¿ƒä¸‹è¼‰é‚è¼¯ ==========

def download_one(args):
    symbol, name, mode = args
    csv_path = os.path.abspath(os.path.join(CACHE_DIR, f"{symbol}.csv"))
    start_date = "2020-01-01" if mode == 'hot' else "1993-01-04"
    
    if not IS_GITHUB_ACTIONS and os.path.exists(csv_path):
        file_age = time.time() - os.path.getmtime(csv_path)
        if file_age < DATA_EXPIRY_SECONDS:
            return {"symbol": symbol, "status": "cache", "data": None}

    try:
        # âœ… ç¸®æ¸›ç­‰å¾…æ™‚é–“ï¼Œå¤šåŸ·è¡Œç·’ä¸‹ 0.2-0.5 ç§’å·²è¶³å¤ é¿é–‹å¤§éƒ¨åˆ†é–å®š
        time.sleep(random.uniform(0.2, 0.5))
        
        tk = yf.Ticker(symbol)
        hist = tk.history(start=start_date, timeout=20, auto_adjust=True)
        
        if hist is None or hist.empty:
            return {"symbol": symbol, "status": "empty", "data": None}
            
        hist.reset_index(inplace=True)
        hist.columns = [c.lower() for c in hist.columns]
        if 'date' in hist.columns:
            hist['date'] = pd.to_datetime(hist['date']).dt.tz_localize(None).dt.strftime('%Y-%m-%d')
        
        df_final = hist[['date', 'open', 'high', 'low', 'close', 'volume']].copy()
        df_final['symbol'] = symbol
        
        # æœ¬åœ°å¿«å–
        if not IS_GITHUB_ACTIONS:
            df_final.to_csv(csv_path, index=False)
            
        return {"symbol": symbol, "status": "success", "data": df_final}
    except Exception:
        return {"symbol": symbol, "status": "error", "data": None}

# ========== 4. ä¸»æµç¨‹ (åŠ å…¥æ‰¹æ¬¡å¯«å…¥) ==========

def run_sync(mode='hot'):
    start_time = time.time()
    init_db()
    
    items = get_tw_stock_list()
    if not items:
        return {"fail_list": [], "success": 0, "has_changed": False}

    log(f"ğŸš€ é–‹å§‹åŒæ­¥ TW | åŸ·è¡Œç·’: {MAX_WORKERS}")

    stats = {"success": 0, "cache": 0, "empty": 0, "error": 0}
    fail_list = []
    
    # å»ºç«‹ä¸€å€‹åˆ—è¡¨ç·©è¡ï¼Œæ¸›å°‘è³‡æ–™åº«é–‹å•Ÿæ¬¡æ•¸
    conn = sqlite3.connect(DB_PATH, timeout=60)
    
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        futures = {executor.submit(download_one, (it[0], it[1], mode)): it[0] for it in items}
        pbar = tqdm(total=len(items), desc=f"TWåŒæ­¥({mode})")
        
        for f in as_completed(futures):
            res = f.result()
            s = res.get("status")
            stats[s] += 1
            
            if s == "success" and res["data"] is not None:
                # âœ… é›†ä¸­åœ¨æ­¤è™•å¯«å…¥ï¼Œæ¸›å°‘é‡è¤‡é€£ç·šé–‹éŠ·
                res["data"].to_sql('stock_prices', conn, if_exists='append', index=False, 
                                 method=lambda table, conn, keys, data_iter: 
                                 conn.executemany(f"INSERT OR REPLACE INTO {table.name} ({', '.join(keys)}) VALUES ({', '.join(['?']*len(keys))})", data_iter))
            
            if s == "error":
                fail_list.append(res.get("symbol"))
            pbar.update(1)
            
        pbar.close()
    
    conn.commit()
    conn.close()

    has_changed = stats['success'] > 0
    if has_changed or IS_GITHUB_ACTIONS:
        log("ğŸ§¹ å„ªåŒ–è³‡æ–™åº« (VACUUM)...")
        conn = sqlite3.connect(DB_PATH)
        conn.execute("VACUUM")
        conn.close()

    duration = (time.time() - start_time) / 60
    log(f"ğŸ“Š åŒæ­¥å®Œæˆï¼è²»æ™‚: {duration:.1f} åˆ†é˜")
    log(f"âœ… æˆåŠŸ: {stats['success']} | âš¡ å¿«å–: {stats['cache']} | âŒ éŒ¯èª¤: {stats['error']}")

    return {
        "success": stats['success'] + stats['cache'],
        "fail_list": fail_list,
        "has_changed": has_changed
    }

if __name__ == "__main__":
    run_sync(mode='hot')
